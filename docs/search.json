[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Welcome to My Website",
    "section": "",
    "text": "Hello, My name is Gisell Bennett! I‚Äôm a Data Analytics major at Baruch College, interested in exploring data and using it to drive meaningful insights. I‚Äôm currently learning various tools and techniques in data analysis, machine learning, and big data technologies."
  },
  {
    "objectID": "index.html#about-me",
    "href": "index.html#about-me",
    "title": "Welcome to My Website",
    "section": "",
    "text": "Hello, My name is Gisell Bennett! I‚Äôm a Data Analytics major at Baruch College, interested in exploring data and using it to drive meaningful insights. I‚Äôm currently learning various tools and techniques in data analysis, machine learning, and big data technologies."
  },
  {
    "objectID": "index.html#skills-im-learning",
    "href": "index.html#skills-im-learning",
    "title": "Welcome to My Website",
    "section": "Skills I‚Äôm Learning",
    "text": "Skills I‚Äôm Learning\nüöÄ Big Data & Cloud Computing: AWS EMR, Apache Spark\n\n\nThank you for visiting! Stay tuned for more updates on my data analytics journey.\n\nLast Updated: Monday 03 03, 2025 at 00:09AM"
  },
  {
    "objectID": "test.html",
    "href": "test.html",
    "title": "Mini Project 1",
    "section": "",
    "text": "nyc_clean &lt;- nyc_payroll %&gt;% mutate(total_salary = base_salary + total_ot_paid + total_other_pay)\n\nChange formatting of certain columns\nnyc_clean &lt;- nyc_clean %&gt;% mutate(across(c(‚Äúagency_name‚Äù, ‚Äúlast_name‚Äù, ‚Äúfirst_name‚Äù, ‚Äúwork_location_borough‚Äù, ‚Äútitle_description‚Äù, ‚Äúleave_status_as_of_june_30‚Äù), str_to_title))\n\n\nCreating career table for Mr.¬†Adams\nadams_career &lt;- nyc_clean %&gt;% filter(first_name == ‚ÄúEric‚Äù, last_name == ‚ÄúAdams‚Äù, mid_init == ‚ÄúL‚Äù) %&gt;% rename( ‚ÄúFiscal Year‚Äù = fiscal_year, ‚ÄúPosition‚Äù = title_description, ‚ÄúAgency‚Äù = agency_name, ‚ÄúTotal Salary‚Äù = total_salary )\nprint(adams_career)"
  },
  {
    "objectID": "docs/MP01.html",
    "href": "docs/MP01.html",
    "title": "NYC Payroll Policy Analysis",
    "section": "",
    "text": "Download Data\nif(!file.exists(‚Äúdata/mp01/nyc_payroll_export.csv‚Äù)){ dir.create(‚Äúdata/mp01‚Äù, showWarnings=FALSE, recursive=TRUE)\nENDPOINT &lt;- \"https://data.cityofnewyork.us/resource/k397-673e.json\"\n\nif(!require(\"httr2\")) install.packages(\"httr2\")\nlibrary(httr2)\n\nif(!require(\"jsonlite\")) install.packages(\"jsonlite\")\nlibrary(jsonlite)\n\nif(!require(\"dplyr\")) install.packages(\"dplyr\")\nlibrary(dplyr)\n\nif(!require(\"readr\")) install.packages(\"readr\")\nlibrary(readr)\n\nBATCH_SIZE &lt;- 50000\nOFFSET     &lt;- 0\nEND_OF_EXPORT &lt;- FALSE\nALL_DATA &lt;- list()\n\nwhile(!END_OF_EXPORT){\n    cat(\"Requesting items\", OFFSET, \"to\", BATCH_SIZE + OFFSET, \"\\n\")\n    \n    req &lt;- request(ENDPOINT) |&gt;\n              req_url_query(`$limit`  = BATCH_SIZE, \n                            `$offset` = OFFSET)\n    \n    resp &lt;- req_perform(req)\n    \n    batch_data &lt;- fromJSON(resp_body_string(resp))\n    \n    ALL_DATA &lt;- c(ALL_DATA, list(batch_data))\n    \n    if(NROW(batch_data) != BATCH_SIZE){\n        END_OF_EXPORT &lt;- TRUE\n        \n        cat(\"End of Data Export Reached\\n\")\n    } else {\n        OFFSET &lt;- OFFSET + BATCH_SIZE\n    }\n}\n\nALL_DATA &lt;- bind_rows(ALL_DATA)\n\ncat(\"Data export complete:\", NROW(ALL_DATA), \"rows and\", NCOL(ALL_DATA), \"columns.\")\n\nwrite_csv(ALL_DATA, \"data/mp01/nyc_payroll_export.csv\")\n}\n\n\nImport and clean the data\nnyc_payroll &lt;- read_csv(‚Äúdata/mp01/nyc_payroll_export.csv‚Äù)\n\n\nAdd a total salary column if it doesn‚Äôt exist\nnyc_clean &lt;- nyc_payroll |&gt; mutate( total_salary = base_salary + total_ot_paid + total_other_pay ) |&gt; mutate( across( c(‚Äúagency_name‚Äù, ‚Äúlast_name‚Äù, ‚Äúfirst_name‚Äù, ‚Äúwork_location_borough‚Äù, ‚Äútitle_description‚Äù, ‚Äúleave_status_as_of_june_30‚Äù), str_to_title ) )\n\n\nTake a glimpse at the cleaned data\nglimpse(nyc_clean)\n\n\nEmployee salary table for Eric L. Adams\nadams_salary_table &lt;- nyc_clean |&gt; filter(first_name == ‚ÄúEric‚Äù, last_name == ‚ÄúAdams‚Äù) |&gt; select(fiscal_year, title_description, agency_name, total_salary)\n\n\nView the result\nprint(adams_salary_table)\n\n\nVisualize salary data using DT\nlibrary(DT)\nadams_salary_table |&gt; mutate(Total Salary = scales::dollar(total_salary)) |&gt; datatable(options = list(searching = FALSE, paging = FALSE, info = FALSE))\n\n\nCompute total compensation for all employees using case_when\nnyc_clean &lt;- nyc_clean |&gt; mutate( hourly_rate = base_salary / 2080, total_compensation = case_when( title_description %in% c(‚ÄúMayor‚Äù) ~ total_salary, !is.na(hourly_rate) & !is.na(regular_hours) & !is.na(ot_hours) ~ (hourly_rate * regular_hours) + (hourly_rate * 1.5 * ot_hours), !is.na(hourly_rate) & !is.na(regular_hours) & is.na(ot_hours) ~ hourly_rate * regular_hours, TRUE ~ NA_real_ ) )\n\n\nView the first few rows to verify the total compensation\nhead(nyc_clean)\n\n\nView the first few rows to check the compensation values\nhead(nyc_clean |&gt; select(first_name, last_name, title_description, total_compensation))\n\n\nCheck for any missing values in total_compensation\nnyc_clean |&gt; filter(is.na(total_compensation))\n\n\nSummarize total compensation for different titles\nnyc_clean |&gt; group_by(title_description) |&gt; summarise( avg_total_compensation = mean(total_compensation, na.rm = TRUE) )\n\n\nWhich job title has the highest base rate of pay? (Assuming a standard 2,000-hour work year and no overtime.) Chair hourly rate $207\nnyc_clean |&gt; mutate(hourly_base_rate = base_salary / 2000) |&gt; arrange(desc(hourly_base_rate)) |&gt; slice(1) |&gt; select(title_description, hourly_base_rate)\n\n\nWhich individual and in what year had the single highest city total payroll (regular and overtime combined)? Mark Tettonis $1,881,523\nnyc_clean |&gt; transform(total_payroll = total_salary + total_ot_paid) |&gt; arrange(desc(total_payroll)) |&gt; slice(1) |&gt; select(fiscal_year, first_name, last_name, total_payroll)\n\n\nWhich individual worked the most overtime hours in this data set? James Internicola 3693 hours\nnyc_clean |&gt; arrange(desc(ot_hours)) |&gt; slice(1) |&gt; select(first_name, last_name, ot_hours)\n\n\nWhich agency has the highest average total annual payroll (base and overtime pay per employee)? Office of Racial Equity $15314\nnyc_clean |&gt; group_by(agency_name) |&gt; summarise(avg_total_payroll = mean(total_salary + total_ot_paid, na.rm = TRUE)) |&gt; arrange(desc(avg_total_payroll)) |&gt; slice(1)\n\n\nWhich agency has the most employees on payroll in each year? Dept of Ed Pedagogical\nnyc_clean |&gt; group_by(fiscal_year, agency_name) |&gt; summarise(employee_count = n()) |&gt; group_by(fiscal_year) |&gt; slice_max(employee_count, n = 1)\n\n\nWhich agency has the highest overtime usage (compared to regular hours)? Board of Election\nnyc_clean |&gt; group_by(agency_name) |&gt; summarise( total_regular_hours = sum(regular_hours, na.rm = TRUE), total_ot_hours = sum(ot_hours, na.rm = TRUE), ot_to_regular_ratio = total_ot_hours / total_regular_hours ) |&gt; arrange(desc(ot_to_regular_ratio)) |&gt; slice(1)\n\n\nWhat is the average salary of employees who work outside the five boroughs? (i.e., whose work_location_borough is not one of the five counties.) $53,734\nnyc_clean |&gt; filter(!(work_location_borough %in% c(‚ÄúManhattan‚Äù, ‚ÄúBrooklyn‚Äù, ‚ÄúQueens‚Äù, ‚ÄúBronx‚Äù, ‚ÄúStaten Island‚Äù))) |&gt; summarise(avg_salary_outside_boroughs = mean(base_salary, na.rm = TRUE))\n\n\nHow much has the city‚Äôs aggregate payroll grown over the past 10 years?\nnyc_clean |&gt; group_by(fiscal_year) |&gt; summarise(aggregate_payroll = sum(total_salary + total_ot_paid, na.rm = TRUE)) |&gt; filter(fiscal_year &gt;= (max(fiscal_year) - 10)) |&gt; arrange(fiscal_year)"
  },
  {
    "objectID": "mp01.html#eric-l.-adams",
    "href": "mp01.html#eric-l.-adams",
    "title": "NYC Payroll Policy Analysis",
    "section": "Eric L. Adams",
    "text": "Eric L. Adams\n\n# Employee salary table for Eric L. Adams\nadams_salary_table &lt;- nyc_clean |&gt;\n  filter(first_name == \"Eric\", last_name == \"Adams\") |&gt;\n  select(fiscal_year, title_description, agency_name, total_salary) |&gt;\n  rename(\n    \"Fiscal Year\" = fiscal_year,\n    \"Position\" = title_description,\n    \"Agency\" = agency_name,\n    \"Total Salary\" = total_salary\n  )\n\nError in rename(select(filter(nyc_clean, first_name == \"Eric\", last_name == : could not find function \"rename\"\n\nlibrary(knitr)\nadams_salary_table |&gt;\n  mutate(`Total Salary` = scales::dollar(`Total Salary`)) |&gt;\n  kable(format = \"html\", col.names = c(\"Fiscal Year\", \"Position\", \"Agency\", \"Total Salary\"))\n\nError in mutate(adams_salary_table, `Total Salary` = scales::dollar(`Total Salary`)): could not find function \"mutate\""
  },
  {
    "objectID": "mp01.html#all-employees-in-our-dataset",
    "href": "mp01.html#all-employees-in-our-dataset",
    "title": "NYC Payroll Policy Analysis",
    "section": "All Employees in our dataset",
    "text": "All Employees in our dataset\n\n# Compute total compensation for all employees using case_when\nnyc_clean &lt;- nyc_clean |&gt;\n  mutate(\n    hourly_rate = base_salary / 2080,\n    total_compensation = case_when(\n      title_description %in% c(\"Mayor\") ~ total_salary,\n      !is.na(hourly_rate) & !is.na(regular_hours) & !is.na(ot_hours) ~ (hourly_rate * regular_hours) + (hourly_rate * 1.5 * ot_hours),\n      !is.na(hourly_rate) & !is.na(regular_hours) & is.na(ot_hours) ~ hourly_rate * regular_hours,\n      TRUE ~ NA_real_\n    )\n  )\n\nError in mutate(nyc_clean, hourly_rate = base_salary/2080, total_compensation = case_when(title_description %in% : could not find function \"mutate\"\n\n# View the first few rows to verify the total compensation\n\nhead(nyc_clean)\n\nError: object 'nyc_clean' not found\n\n# View the first few rows to check the compensation values\nhead(nyc_clean |&gt;\n       select(first_name, last_name, title_description, total_compensation))\n\nError in select(nyc_clean, first_name, last_name, title_description, total_compensation): could not find function \"select\"\n\n# Check for any missing values in total_compensation\nnyc_clean |&gt;\n  filter(is.na(total_compensation))\n\nError: object 'nyc_clean' not found\n\n# Summarize total compensation for different titles\n\nnyc_clean |&gt;\n  group_by(title_description) |&gt;\n  summarise(\n    avg_total_compensation = mean(total_compensation, na.rm = TRUE)\n  )\n\nError in summarise(group_by(nyc_clean, title_description), avg_total_compensation = mean(total_compensation, : could not find function \"summarise\""
  },
  {
    "objectID": "mp01.html#instructor-provided-questions",
    "href": "mp01.html#instructor-provided-questions",
    "title": "Mini Project 1",
    "section": "Instructor Provided Questions",
    "text": "Instructor Provided Questions"
  },
  {
    "objectID": "rest.html",
    "href": "rest.html",
    "title": "Mini Project 1",
    "section": "",
    "text": "New York City‚Äôs payroll expenses form a major part of its budget, prompting the Commission to Analyze Taxpayer Spending (CATS) to explore cost-saving policies. This project evaluates three proposals: capping salaries at the mayoral level, increasing staffing to reduce overtime costs, and implementing a custom policy to control excessive overtime pay. Using NYC payroll data and R for analysis, we assess each policy‚Äôs financial impact and feasibility. The findings will guide policymakers in optimizing taxpayer spending while maintaining city services."
  },
  {
    "objectID": "rest.html#github-documents",
    "href": "rest.html#github-documents",
    "title": "Mini Project 1",
    "section": "",
    "text": "This is an R Markdown format used for publishing markdown documents to GitHub. When you click the Knit button all R code chunks are run and a markdown file (.md) suitable for publishing to GitHub is generated."
  },
  {
    "objectID": "rest.html#including-code",
    "href": "rest.html#including-code",
    "title": "Mini Project 1",
    "section": "Including Code",
    "text": "Including Code\nData Acquisition and :\n\nif(!file.exists(\"data/mp01/nyc_payroll_export.csv\")){\n  dir.create(\"data/mp01\", showWarnings=FALSE, recursive=TRUE)\n  \n  ENDPOINT &lt;- \"https://data.cityofnewyork.us/resource/k397-673e.json\"\n  \n  if(!require(\"httr2\")) install.packages(\"httr2\")\n  library(httr2)\n  \n  if(!require(\"jsonlite\")) install.packages(\"jsonlite\")\n  library(jsonlite)\n  \n  if(!require(\"dplyr\")) install.packages(\"dplyr\")\n  library(dplyr)\n  \n  if(!require(\"readr\")) install.packages(\"readr\")\n  library(readr)\n  \n  BATCH_SIZE &lt;- 50000\n  OFFSET     &lt;- 0\n  END_OF_EXPORT &lt;- FALSE\n  ALL_DATA &lt;- list()\n  \n  while(!END_OF_EXPORT){\n    cat(\"Requesting items\", OFFSET, \"to\", BATCH_SIZE + OFFSET, \"\\n\")\n    \n    req &lt;- request(ENDPOINT) |&gt;\n      req_url_query(`$limit`  = BATCH_SIZE, \n                    `$offset` = OFFSET)\n    \n    resp &lt;- req_perform(req)\n    \n    batch_data &lt;- fromJSON(resp_body_string(resp))\n    \n    ALL_DATA &lt;- c(ALL_DATA, list(batch_data))\n    \n    if(NROW(batch_data) != BATCH_SIZE){\n      END_OF_EXPORT &lt;- TRUE\n      \n      cat(\"End of Data Export Reached\\n\")\n    } else {\n      OFFSET &lt;- OFFSET + BATCH_SIZE\n    }\n  }\n  \n  ALL_DATA &lt;- bind_rows(ALL_DATA)\n  \n  cat(\"Data export complete:\", NROW(ALL_DATA), \"rows and\", NCOL(ALL_DATA), \"columns.\")\n  \n  write_csv(ALL_DATA, \"data/mp01/nyc_payroll_export.csv\")\n}"
  },
  {
    "objectID": "rest.html#including-plots",
    "href": "rest.html#including-plots",
    "title": "Mini Project 1",
    "section": "Including Plots",
    "text": "Including Plots\nYou can also embed plots, for example:\n\n\n\n\n\n\n\n\n\nNote that the echo = FALSE parameter was added to the code chunk to prevent printing of the R code that generated the plot."
  },
  {
    "objectID": "rest.html#introduction",
    "href": "rest.html#introduction",
    "title": "Mini Project 1",
    "section": "Introduction",
    "text": "Introduction\nNew York City‚Äôs payroll expenses form a major part of its budget, prompting the Commission to Analyze Taxpayer Spending (CATS) to explore cost-saving policies. This project evaluates three proposals: capping salaries at the mayoral level, increasing staffing to reduce overtime costs, and implementing a custom policy to control excessive overtime pay. Using NYC payroll data and R for analysis, we assess each policy‚Äôs financial impact and feasibility. The findings will guide policymakers in optimizing taxpayer spending while maintaining city services."
  },
  {
    "objectID": "rest.html#acquiring-payroll-data",
    "href": "rest.html#acquiring-payroll-data",
    "title": "Mini Project 1",
    "section": "Acquiring Payroll Data",
    "text": "Acquiring Payroll Data"
  },
  {
    "objectID": "rest.html#data-preparation-and-cleaning",
    "href": "rest.html#data-preparation-and-cleaning",
    "title": "Mini Project 1",
    "section": "Data Preparation and Cleaning",
    "text": "Data Preparation and Cleaning\n#Initial Exploration # Eric L. Adams Salary Table\n\nEmployee Compensation Analysis\nEmployee Compensation Table"
  },
  {
    "objectID": "rest.html#initial-exploration",
    "href": "rest.html#initial-exploration",
    "title": "Mini Project 1",
    "section": "Initial Exploration",
    "text": "Initial Exploration\n\nEric L. Adams Salary Table\n\n\nEmployee Compensation Analysis"
  },
  {
    "objectID": "rest.html#instructor-provided-questions",
    "href": "rest.html#instructor-provided-questions",
    "title": "Mini Project 1",
    "section": "Instructor Provided Questions",
    "text": "Instructor Provided Questions\n\n\n# A tibble: 1 √ó 2\n  title_description hourly_base_rate\n  &lt;chr&gt;                        &lt;dbl&gt;\n1 Chair                         207.\n\n\n  fiscal_year first_name last_name total_payroll\n1        2024       Mark  Tettonis       1881523\n\n\n# A tibble: 1 √ó 3\n  first_name last_name   ot_hours\n  &lt;chr&gt;      &lt;chr&gt;          &lt;dbl&gt;\n1 James      Internicola    3693.\n\n\n# A tibble: 1 √ó 2\n  agency_name             avg_total_payroll\n  &lt;chr&gt;                               &lt;dbl&gt;\n1 Office Of Racial Equity           153134.\n\n\n# A tibble: 11 √ó 3\n# Groups:   fiscal_year [11]\n   fiscal_year agency_name            employee_count\n         &lt;dbl&gt; &lt;chr&gt;                           &lt;int&gt;\n 1        2014 Dept Of Ed Pedagogical         100589\n 2        2015 Dept Of Ed Pedagogical         111857\n 3        2016 Dept Of Ed Pedagogical         106263\n 4        2017 Dept Of Ed Pedagogical         104629\n 5        2018 Dept Of Ed Pedagogical         107956\n 6        2019 Dept Of Ed Pedagogical         112067\n 7        2020 Dept Of Ed Pedagogical         114999\n 8        2021 Dept Of Ed Pedagogical         113523\n 9        2022 Dept Of Ed Pedagogical         120453\n10        2023 Dept Of Ed Pedagogical         106882\n11        2024 Dept Of Ed Pedagogical         108209\n\n\n# A tibble: 1 √ó 4\n  agency_name       total_regular_hours total_ot_hours ot_to_regular_ratio\n  &lt;chr&gt;                           &lt;dbl&gt;          &lt;dbl&gt;               &lt;dbl&gt;\n1 Board Of Election           15339960.       3062029.               0.200\n\n\n# A tibble: 1 √ó 1\n  avg_salary_outside_boroughs\n                        &lt;dbl&gt;\n1                      53734.\n\n\n# A tibble: 11 √ó 2\n   fiscal_year aggregate_payroll\n         &lt;dbl&gt;             &lt;dbl&gt;\n 1        2014      24172586330.\n 2        2015      27173046540.\n 3        2016      28392240168.\n 4        2017      29195556714.\n 5        2018      29864346806.\n 6        2019      31374613682.\n 7        2020      34565222187.\n 8        2021      33330917876.\n 9        2022      37319692054.\n10        2023      35873673474.\n11        2024      36662138291."
  },
  {
    "objectID": "rest.html#analysis",
    "href": "rest.html#analysis",
    "title": "Mini Project 1",
    "section": "Analysis",
    "text": "Analysis\nEffective management of New York City payroll is crucial for maintaining fiscal responsibility and ensuring optimal allocation of taxpayer money. The City Agency for Transportation Services (CATS) is committed to exploring policy reforms that can enhance efficiency and reduce expenditures without compromising service quality. This analysis examines three proposed policies aimed at achieving these objectives:\n\nPolicy I: Capping Salaries at Mayoral Level\nPolicy II: Increasing Staffing to Reduce Overtime Expenses\nPolicy III: Implementing Performance-Based Pay Adjustments"
  },
  {
    "objectID": "mp01.html#introduction",
    "href": "mp01.html#introduction",
    "title": "Mini Project 1",
    "section": "",
    "text": "New York City‚Äôs payroll expenses form a major part of its budget, prompting the Commission to Analyze Taxpayer Spending (CATS) to explore cost-saving policies. This project evaluates three proposals: capping salaries at the mayoral level, increasing staffing to reduce overtime costs, and implementing a custom policy to control excessive overtime pay. Using NYC payroll data and R for analysis, we assess each policy‚Äôs financial impact and feasibility. The findings will guide policymakers in optimizing taxpayer spending while maintaining city services."
  },
  {
    "objectID": "mp01.html#acquiring-payroll-data",
    "href": "mp01.html#acquiring-payroll-data",
    "title": "Mini Project 1",
    "section": "Acquiring Payroll Data",
    "text": "Acquiring Payroll Data\n\nif(!file.exists(\"data/mp01/nyc_payroll_export.csv\")){\n  dir.create(\"data/mp01\", showWarnings=FALSE, recursive=TRUE)\n  \n  ENDPOINT &lt;- \"https://data.cityofnewyork.us/resource/k397-673e.json\"\n  \n  if(!require(\"httr2\")) install.packages(\"httr2\")\n  library(httr2)\n  \n  if(!require(\"jsonlite\")) install.packages(\"jsonlite\")\n  library(jsonlite)\n  \n  if(!require(\"dplyr\")) install.packages(\"dplyr\")\n  library(dplyr)\n  \n  if(!require(\"readr\")) install.packages(\"readr\")\n  library(readr)\n  \n  BATCH_SIZE &lt;- 50000\n  OFFSET     &lt;- 0\n  END_OF_EXPORT &lt;- FALSE\n  ALL_DATA &lt;- list()\n  \n  while(!END_OF_EXPORT){\n    req &lt;- request(ENDPOINT) |&gt;\n      req_url_query(`$limit`  = BATCH_SIZE, \n                    `$offset` = OFFSET)\n    \n    resp &lt;- req_perform(req)\n    batch_data &lt;- fromJSON(resp_body_string(resp))\n    ALL_DATA &lt;- c(ALL_DATA, list(batch_data))\n    \n    if(NROW(batch_data) != BATCH_SIZE){\n      END_OF_EXPORT &lt;- TRUE\n    } else {\n      OFFSET &lt;- OFFSET + BATCH_SIZE\n    }\n  }\n  \n  ALL_DATA &lt;- bind_rows(ALL_DATA)\n  write_csv(ALL_DATA, \"data/mp01/nyc_payroll_export.csv\")\n}"
  },
  {
    "objectID": "mp01.html#data-preparation-and-cleaning",
    "href": "mp01.html#data-preparation-and-cleaning",
    "title": "Mini Project 1",
    "section": "Data Preparation and Cleaning",
    "text": "Data Preparation and Cleaning\n\nlibrary(readr)\nlibrary(dplyr)\n## \n## Attaching package: 'dplyr'\n## The following objects are masked from 'package:stats':\n## \n##     filter, lag\n## The following objects are masked from 'package:base':\n## \n##     intersect, setdiff, setequal, union\nlibrary(stringr)\n\nnyc_payroll &lt;- read_csv(\"data/mp01/nyc_payroll_export.csv\")\n## Rows: 6225611 Columns: 17\n## ‚îÄ‚îÄ Column specification ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n## Delimiter: \",\"\n## chr  (8): agency_name, last_name, first_name, mid_init, work_location_boroug...\n## dbl  (8): fiscal_year, payroll_number, base_salary, regular_hours, regular_g...\n## dttm (1): agency_start_date\n## \n## ‚Ñπ Use `spec()` to retrieve the full column specification for this data.\n## ‚Ñπ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\nnyc_clean &lt;- nyc_payroll |&gt;\n  mutate(\n    total_salary = base_salary + total_ot_paid + total_other_pay\n  ) |&gt;\n  mutate(\n    across(\n      c(\"agency_name\", \"last_name\", \"first_name\", \"work_location_borough\", \n        \"title_description\", \"leave_status_as_of_june_30\"), \n      str_to_title\n    )\n  )\n\n#Initial Exploration # Eric L. Adams Salary Table\n\nlibrary(knitr)\nadams_salary_table &lt;- nyc_clean |&gt;\n  filter(first_name == \"Eric\", last_name == \"Adams\") |&gt;\n  select(fiscal_year, title_description, agency_name, total_salary) |&gt;\n  rename(\n    \"Fiscal Year\" = fiscal_year,\n    \"Position\" = title_description,\n    \"Agency\" = agency_name,\n    \"Total Salary\" = total_salary\n  )\nkable(adams_salary_table)\n\n\n\n\n\n\n\n\n\n\nFiscal Year\nPosition\nAgency\nTotal Salary\n\n\n\n\n2022\nBorough President\nBorough President-Brooklyn\n179200.62\n\n\n2021\nBorough President\nBorough President-Brooklyn\n179200.00\n\n\n2020\nBorough President\nBorough President-Brooklyn\n179200.00\n\n\n2019\nBorough President\nBorough President-Brooklyn\n179200.00\n\n\n2018\nBorough President\nBorough President-Brooklyn\n179200.00\n\n\n2017\nBorough President\nBorough President-Brooklyn\n179200.00\n\n\n2016\nBorough President\nBorough President-Brooklyn\n179200.00\n\n\n2015\nBorough President\nBorough President-Brooklyn\n160000.00\n\n\n2014\nBorough President\nBorough President-Brooklyn\n160000.00\n\n\n2020\nJob Training Participant\nDept Of Parks & Recreation\n404.64\n\n\n2019\nJob Training Participant\nDept Of Parks & Recreation\n310.76\n\n\n2018\nJob Training Participant\nDept Of Parks & Recreation\n165.90\n\n\n2024\nMayor\nOffice Of The Mayor\n258750.00\n\n\n2023\nMayor\nOffice Of The Mayor\n258750.00\n\n\n2022\nMayor\nOffice Of The Mayor\n258750.00\n\n\n2024\nPolice Officer\nPolice Department\n88906.04\n\n\n2023\nPolice Officer\nPolice Department\n75896.35\n\n\n2022\nPolice Officer\nPolice Department\n59914.87\n\n\n2021\nPolice Officer\nPolice Department\n43788.14\n\n\n\n\n\n\nEmployee Compensation Analysis\nEmployee Compensation Table\n\nnyc_clean &lt;- nyc_clean |&gt;\n  mutate(\n    hourly_rate = base_salary / 2080,\n    total_compensation = case_when(\n      title_description %in% c(\"Mayor\") ~ total_salary,\n      !is.na(hourly_rate) & !is.na(regular_hours) & !is.na(ot_hours) ~ (hourly_rate * regular_hours) + (hourly_rate * 1.5 * ot_hours),\n      !is.na(hourly_rate) & !is.na(regular_hours) & is.na(ot_hours) ~ hourly_rate * regular_hours,\n      TRUE ~ NA_real_\n    )\n  )\nkable(head(nyc_clean))\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nfiscal_year\npayroll_number\nagency_name\nlast_name\nfirst_name\nmid_init\nagency_start_date\nwork_location_borough\ntitle_description\nleave_status_as_of_june_30\nbase_salary\npay_basis\nregular_hours\nregular_gross_paid\not_hours\ntotal_ot_paid\ntotal_other_pay\ntotal_salary\nhourly_rate\ntotal_compensation\n\n\n\n\n2024\n67\nAdmin For Children‚Äôs Svcs\nFaye Fall\nSokhna\nM\n2023-11-20\nBronx\nChild Protective Specialist\nActive\n62043\nper Annum\n1050.00\n31267.96\n12.00\n425.00\n78.04\n62546.04\n29.82837\n31856.69\n\n\n2024\n67\nAdmin For Children‚Äôs Svcs\nKilgore\nOrlantha\nB\n2023-08-28\nBrooklyn\nChild Protective Specialist\nActive\n62043\nper Annum\n1470.00\n44660.96\n99.75\n3859.84\n78.14\n65980.98\n29.82837\n48310.77\n\n\n2024\n67\nAdmin For Children‚Äôs Svcs\nWisdom\nCherise\nM\n2022-10-24\nManhattan\nCommunity Associate\nOn Leave\n43144\nper Annum\n1251.50\n28649.20\n30.00\n802.42\n78.26\n44024.68\n20.74231\n26892.40\n\n\n2024\n67\nAdmin For Children‚Äôs Svcs\nMiller\nMoya-Gaye\nS\n2023-02-27\nManhattan\nChild Protective Specialist\nOn Leave\n62043\nper Annum\n1400.75\n44515.43\n44.75\n1476.98\n78.37\n63598.35\n29.82837\n43784.31\n\n\n2024\n67\nAdmin For Children‚Äôs Svcs\nBradley\nYashika\nM\n2023-02-27\nBronx\nChild Protective Specialist\nCeased\n60236\nper Annum\n700.00\n22133.64\n53.00\n1933.33\n78.47\n62247.80\n28.95962\n22574.02\n\n\n2024\n67\nAdmin For Children‚Äôs Svcs\nMaurino\nJennifer\nL\n2023-08-28\nRichmond\nChild Protective Specialist\nActive\n62043\nper Annum\n1470.00\n45940.44\n146.00\n5596.49\n78.86\n67718.35\n29.82837\n50380.11"
  },
  {
    "objectID": "mp01.html#analysis",
    "href": "mp01.html#analysis",
    "title": "Mini Project 1",
    "section": "Analysis",
    "text": "Analysis\nEffective management of New York City payroll is crucial for maintaining fiscal responsibility and ensuring optimal allocation of taxpayer money. The City Agency for Transportation Services (CATS) is committed to exploring policy reforms that can enhance efficiency and reduce expenditures without compromising service quality. This analysis examines three proposed policies aimed at achieving these objectives:\n\nPolicy I: Capping Salaries at Mayoral Level\nPolicy II: Increasing Staffing to Reduce Overtime Expenses\nPolicy III: Implementing Performance-Based Pay Adjustments"
  },
  {
    "objectID": "mp01.html",
    "href": "mp01.html",
    "title": "Mini Project 1",
    "section": "",
    "text": "New York City‚Äôs payroll expenses form a major part of its budget, prompting the Commission to Analyze Taxpayer Spending (CATS) to explore cost-saving policies. This project evaluates three proposals: capping salaries at the mayoral level, increasing staffing to reduce overtime costs, and implementing a custom policy to control excessive overtime pay. Using NYC payroll data and R for analysis, we assess each policy‚Äôs financial impact and feasibility. The findings will guide policymakers in optimizing taxpayer spending while maintaining city services."
  },
  {
    "objectID": "FinalProject.html#nyc-doe-open-data",
    "href": "FinalProject.html#nyc-doe-open-data",
    "title": "Final Project Proposal",
    "section": "NYC DOE Open Data",
    "text": "NYC DOE Open Data\n\nSchool funding and budget data: This will provide insights into how much money each school or district receives.\nStudent performance data: Look for data on standardized test scores (e.g., NYS Regents exams), graduation rates, and academic progress.\nStudent demographics: Data on enrollment numbers, student diversity (race/ethnicity), and socioeconomic status (e.g., free/reduced lunch eligibility).\nSchool resources: Data on teacher-student ratios, availability of advanced placement courses, extracurricular programs, etc."
  },
  {
    "objectID": "FinalProject.html#nysed-data",
    "href": "FinalProject.html#nysed-data",
    "title": "Final Project Proposal",
    "section": "NYSED Data",
    "text": "NYSED Data\n\nData on school performance (test scores, graduation rates, etc.)\nReports on funding formulas and how schools are allocated resources\nReports and statistics on school equity, teacher qualification data, and student performance by district."
  },
  {
    "objectID": "FinalProject.html#the-college-board",
    "href": "FinalProject.html#the-college-board",
    "title": "Final Project Proposal",
    "section": "The College Board",
    "text": "The College Board\n\nData on SAT/ACT scores by school or district\nCollege readiness and participation data\nAP exam performance by region or school"
  },
  {
    "objectID": "FinalProject.html#access-to-relevant-data-on-school-facilities",
    "href": "FinalProject.html#access-to-relevant-data-on-school-facilities",
    "title": "Final Project Proposal",
    "section": "Access to Relevant Data on School Facilities",
    "text": "Access to Relevant Data on School Facilities\nChallenge: School facility data (such as the availability of technology, classroom conditions, extracurricular opportunities) might not always be publicly available or could vary widely across schools, making it harder to quantify access."
  },
  {
    "objectID": "FinalProject.html#sample-bias-in-educational-data",
    "href": "FinalProject.html#sample-bias-in-educational-data",
    "title": "Final Project Proposal",
    "section": "Sample Bias in Educational Data",
    "text": "Sample Bias in Educational Data\nChallenge: The data you are analyzing might be biased if certain schools or districts are over- or underrepresented in the data sources. For instance, certain districts may have more resources for data collection and reporting, skewing the results."
  },
  {
    "objectID": "mp02.html",
    "href": "mp02.html",
    "title": "Mini Project 2",
    "section": "",
    "text": "Public transit systems reduce urban congestion and offer sustainable alternatives to personal vehicles. However, environmental efficiency varies across systems due to ridership, travel distances, and emissions. This project evaluates the environmental efficiency of U.S. public transit systems using data from the National Transit Database (NTD) and the U.S. Energy Information Administration (EIA) State Electricity Profiles.\nKey areas of analysis include:\n\nRidership levels across transit agencies\nAverage travel distances per passenger\nEmissions associated with different transit modes\n\nThis study aims to identify sustainability trends and potential areas for reducing transit-related emissions."
  },
  {
    "objectID": "mp02.html#data-acquisition",
    "href": "mp02.html#data-acquisition",
    "title": "Mini Project 2",
    "section": "",
    "text": "The first step is to gather relevant datasets. The EIA State Electricity Profile will be used to estimate the environmental impact of electricity consumption in transit systems.\n\n## Loading required package: scales\n## \n## Attaching package: 'scales'\n## The following object is masked from 'package:purrr':\n## \n##     discard\n\n\n\n\n\nWe‚Äôve collected data on effective emissions per MWh¬≤, electricity prices, and total statewide generation capacity. This will help us compare emissions across different public transit modes. Before exploring the National Transit Database for details on various transit agencies, let‚Äôs first analyze the SEP data and address a few key questions."
  },
  {
    "objectID": "mp02.html#r-markdown",
    "href": "mp02.html#r-markdown",
    "title": "Mini Project 2: Identifying Environmentally Responsible US Public Transit Systems",
    "section": "",
    "text": "This is an R Markdown document. Markdown is a simple formatting syntax for authoring HTML, PDF, and MS Word documents. For more details on using R Markdown see http://rmarkdown.rstudio.com.\nWhen you click the Knit button a document will be generated that includes both content as well as the output of any embedded R code chunks within the document. You can embed an R code chunk like this:\n\nsummary(cars)\n\n     speed           dist       \n Min.   : 4.0   Min.   :  2.00  \n 1st Qu.:12.0   1st Qu.: 26.00  \n Median :15.0   Median : 36.00  \n Mean   :15.4   Mean   : 42.98  \n 3rd Qu.:19.0   3rd Qu.: 56.00  \n Max.   :25.0   Max.   :120.00"
  },
  {
    "objectID": "mp02.html#including-plots",
    "href": "mp02.html#including-plots",
    "title": "Mini Project 2: Identifying Environmentally Responsible US Public Transit Systems",
    "section": "",
    "text": "You can also embed plots, for example:\n\n\n\n\n\n\n\n\n\nNote that the echo = FALSE parameter was added to the code chunk to prevent printing of the R code that generated the plot."
  },
  {
    "objectID": "mp02.html#which-state-has-the-most-expensive-retail-electricity",
    "href": "mp02.html#which-state-has-the-most-expensive-retail-electricity",
    "title": "Mini Project 2",
    "section": "",
    "text": "most_expensive_state &lt;- EIA_SEP_REPORT |&gt; \n  arrange(desc(electricity_price_MWh)) |&gt; \n  slice(1) |&gt; \n  select(state, electricity_price_MWh)\n\nprint(most_expensive_state)\n##    state electricity_price_MWh\n## 1 Hawaii                   386"
  },
  {
    "objectID": "mp02.html#key-questions",
    "href": "mp02.html#key-questions",
    "title": "Mini Project 2",
    "section": "Key Questions",
    "text": "Key Questions\n\nWhich state has the most expensive retail electricity?\n\n\n##    state electricity_price_MWh\n## 1 Hawaii                   386\n\n\nWhich state has the ‚Äòdirtiest‚Äô electricity mix?\n\n\n##           state CO2_MWh\n## 1 West Virginia    1925\n\n\nOn average, how many pounds of CO2 are emitted per MWh of electricity produced in the US? (Note that you will need to use a suitably weighted average here.)\n\n\n## [1] 805.3703\n\n\nWhat is the rarest primary energy source in the US? What is the associated cost of electricity and where is it used?\n\n\n##    state primary_source electricity_price_MWh\n## 1 Hawaii      Petroleum                   386\n\n\nTexas, has a reputation as being the home of ‚Äúdirty fossil fuels‚Äù while NY has a reputation as a leader in clean energy. How many times cleaner is NY‚Äôs energy mix than that of Texas?\n\n\n## [1] 1.637931"
  },
  {
    "objectID": "mp02.html#energy-consumption",
    "href": "mp02.html#energy-consumption",
    "title": "Mini Project 2",
    "section": "Energy Consumption",
    "text": "Energy Consumption\nNext, we will load, clean, and transform the 2023 Energy Consumption dataset by removing unnecessary columns, converting non-numeric values to numeric, grouping by key attributes, and filtering out irrelevant rows. A random sample of the cleaned data will then be displayed.\n\n## Loading required package: readxl\n## Warning: package 'readxl' was built under R version 4.4.3\n## Warning: Expecting numeric in R1197 / R1197C18: got '-'\n\n\n## Loading required package: tidyr\n## # A tibble: 10 √ó 16\n##    `NTD ID` Mode  `Agency Name`       `Bio-Diesel` `Bunker Fuel` `C Natural Gas`\n##       &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt;                      &lt;dbl&gt;         &lt;dbl&gt;           &lt;dbl&gt;\n##  1    50015 LR    The Greater Clevel‚Ä¶            0             0               0\n##  2    50149 DR    Michiana Area Coun‚Ä¶            0             0               0\n##  3    40171 DR    Knoxville-Knox Cou‚Ä¶            0             0               0\n##  4    50035 DR    Central County Tra‚Ä¶            0             0               0\n##  5    90031 DR    Riverside Transit ‚Ä¶            0             0               0\n##  6    40044 MB    City of Montgomery         19733             0               0\n##  7        2 DR    Spokane Transit Au‚Ä¶            0             0               0\n##  8    70271 SR    Kansas City, City ‚Ä¶            0             0               0\n##  9    40018 MB    Transit Authority ‚Ä¶      1425558             0               0\n## 10    70275 VP    Nebraska Departmen‚Ä¶            0             0               0\n## # ‚Ñπ 10 more variables: `Diesel Fuel` &lt;dbl&gt;, `Electric Battery` &lt;dbl&gt;,\n## #   `Electric Propulsion` &lt;dbl&gt;, Ethanol &lt;dbl&gt;, Methonal &lt;dbl&gt;, Gasoline &lt;dbl&gt;,\n## #   Hydrogen &lt;dbl&gt;, Kerosene &lt;dbl&gt;, `Liquified Nat Gas` &lt;dbl&gt;,\n## #   `Liquified Petroleum Gas` &lt;dbl&gt;"
  },
  {
    "objectID": "mp02.html#state-electricity-profiles",
    "href": "mp02.html#state-electricity-profiles",
    "title": "Mini Project 2",
    "section": "State Electricity Profiles",
    "text": "State Electricity Profiles\nWe use EIA‚Äôs State Electricity Profiles to estimate the environmental impact of electricity use in transit systems.\n\nInstall and Load Required Packages\n\n\nRetrieve and Process EIA Data\n\n\nData Summary\n\n\n\n\n\n\n\n\nCO2 Emissions per MWh by State\nThis bar plot illustrates the CO2 emissions per megawatt-hour (MWh) by state, helping to identify regions with higher emissions relative to energy production.\n\n\n\n\n\n\n\n\n\nWe‚Äôve collected data on effective emissions per MWh¬≤, electricity prices, and total statewide generation capacity. This will help us compare emissions across different public transit modes. Before exploring the National Transit Database for details on various transit agencies, let‚Äôs first analyze the SEP data and address a few key questions.\n\nKey Questions\n\nWhich state has the most expensive retail electricity?\n\n\n##    state electricity_price_MWh\n## 1 Hawaii                   386\n\n\nWhich state has the ‚Äòdirtiest‚Äô electricity mix?\n\n\n##           state CO2_MWh\n## 1 West Virginia    1925\n\n\nOn average, how many pounds of CO2 are emitted per MWh of electricity produced in the US? (Note that you will need to use a suitably weighted average here.)\n\n\n## [1] 805.3703\n\n\nWhat is the rarest primary energy source in the US? What is the associated cost of electricity and where is it used?\n\n\n##    state primary_source electricity_price_MWh\n## 1 Hawaii      Petroleum                   386\n\n\nTexas, has a reputation as being the home of ‚Äúdirty fossil fuels‚Äù while NY has a reputation as a leader in clean energy. How many times cleaner is NY‚Äôs energy mix than that of Texas?\n\n\n## [1] 1.637931\n\n\n\n2023 Annual Database Energy Consumption\nNext, we will load, clean, and transform the 2023 Energy Consumption dataset by removing unnecessary columns, converting non-numeric values to numeric, grouping by key attributes, and filtering out irrelevant rows. A random sample of the cleaned data will then be displayed.\n\n## # A tibble: 10 √ó 16\n##    `NTD ID` Mode  `Agency Name`       `Bio-Diesel` `Bunker Fuel` `C Natural Gas`\n##       &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt;                      &lt;dbl&gt;         &lt;dbl&gt;           &lt;dbl&gt;\n##  1    90062 MB    Monterey-Salinas T‚Ä¶            0             0               0\n##  2    50110 DR    Bloomington Public‚Ä¶            0             0               0\n##  3    60130 MB    Alamo Area Council‚Ä¶            0             0               0\n##  4    80001 LR    Utah Transit Autho‚Ä¶            0             0               0\n##  5    90015 LR    City and County of‚Ä¶            0             0               0\n##  6    60008 LR    Metropolitan Trans‚Ä¶            0             0               0\n##  7    90002 MB    City and County of‚Ä¶            0             0               0\n##  8    10040 MB    Southeast Area Tra‚Ä¶        16606             0               0\n##  9    40041 MB    Hillsborough Area ‚Ä¶            0             0         1371713\n## 10    50006 MB    City of Racine, Wi‚Ä¶            0             0               0\n## # ‚Ñπ 10 more variables: `Diesel Fuel` &lt;dbl&gt;, `Electric Battery` &lt;dbl&gt;,\n## #   `Electric Propulsion` &lt;dbl&gt;, Ethanol &lt;dbl&gt;, Methonal &lt;dbl&gt;, Gasoline &lt;dbl&gt;,\n## #   Hydrogen &lt;dbl&gt;, Kerosene &lt;dbl&gt;, `Liquified Nat Gas` &lt;dbl&gt;,\n## #   `Liquified Petroleum Gas` &lt;dbl&gt;\n\n\n\n2023 Annual Database Service by Agency\nLastly, we will download the 2023 Service by Agency report, which contains data on the characteristics of typical passenger trips for each transit service. This data will help us analyze key factors such as ridership, service frequency, and route details for various transit agencies.\n\n## Rows: 302\n## Columns: 6\n## $ Agency   &lt;chr&gt; \"King County, dba: King County Metro\", \"Spokane Transit Autho‚Ä¶\n## $ City     &lt;chr&gt; \"Seattle\", \"Spokane\", \"Lakewood\", \"Everett\", \"Yakima\", \"Eugen‚Ä¶\n## $ State    &lt;chr&gt; \"WA\", \"WA\", \"WA\", \"WA\", \"WA\", \"OR\", \"OR\", \"ID\", \"AK\", \"WA\", \"‚Ä¶\n## $ UPT      &lt;dbl&gt; 78886848, 9403739, 6792245, 1404970, 646711, 6311613, 5744265‚Ä¶\n## $ MILES    &lt;dbl&gt; 301530502, 46318134, 40362320, 5193721, 3435365, 22779952, 23‚Ä¶\n## $ `NTD ID` &lt;dbl&gt; 1, 2, 3, 5, 6, 7, 8, 11, 12, 16, 18, 19, 20, 21, 23, 24, 25, ‚Ä¶\n\n\n\nKey Questions\n1.Which transit service has the most UPT annually?\n\n##                        Agency        UPT\n## 196 MTA New York City Transit 2632003044\n\n2.What is the average trip length of a trip on MTA NYC?\n\n## [1] NaN\n\n3.Which transit service in NYC has the longest average trip length?\n\n##                               Agency   MILES    UPT avg_trip_length\n## 2 Private Transportation Corporation 1244928 237882        5.233385\n\n\nWhich state has the fewest total miles travelled by public transit?\n\n\n##    State   MILES\n## 19    NH 3749892\n\n\nAre all states represented in this data? If no, which ones are missing?\n\n\n##  [1] \"Alabama\"        \"Alaska\"         \"Arizona\"        \"Arkansas\"      \n##  [5] \"California\"     \"Colorado\"       \"Connecticut\"    \"Delaware\"      \n##  [9] \"Florida\"        \"Georgia\"        \"Hawaii\"         \"Idaho\"         \n## [13] \"Illinois\"       \"Indiana\"        \"Iowa\"           \"Kansas\"        \n## [17] \"Kentucky\"       \"Louisiana\"      \"Maine\"          \"Maryland\"      \n## [21] \"Massachusetts\"  \"Michigan\"       \"Minnesota\"      \"Mississippi\"   \n## [25] \"Missouri\"       \"Montana\"        \"Nebraska\"       \"Nevada\"        \n## [29] \"New Hampshire\"  \"New Jersey\"     \"New Mexico\"     \"New York\"      \n## [33] \"North Carolina\" \"North Dakota\"   \"Ohio\"           \"Oklahoma\"      \n## [37] \"Oregon\"         \"Pennsylvania\"   \"Rhode Island\"   \"South Carolina\"\n## [41] \"South Dakota\"   \"Tennessee\"      \"Texas\"          \"Utah\"          \n## [45] \"Vermont\"        \"Virginia\"       \"Washington\"     \"West Virginia\" \n## [49] \"Wisconsin\"      \"Wyoming\""
  },
  {
    "objectID": "mp02.html#annual-database-energy-consumption",
    "href": "mp02.html#annual-database-energy-consumption",
    "title": "Mini Project 2",
    "section": "2023 Annual Database Energy Consumption",
    "text": "2023 Annual Database Energy Consumption\nNext, we will load, clean, and transform the 2023 Energy Consumption dataset by removing unnecessary columns, converting non-numeric values to numeric, grouping by key attributes, and filtering out irrelevant rows. A random sample of the cleaned data will then be displayed.\n\n## Loading required package: readxl\n## Warning: package 'readxl' was built under R version 4.4.3\n## Warning: Expecting numeric in R1197 / R1197C18: got '-'\n\n\n## Loading required package: tidyr\n## # A tibble: 10 √ó 16\n##    `NTD ID` Mode  `Agency Name`       `Bio-Diesel` `Bunker Fuel` `C Natural Gas`\n##       &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt;                      &lt;dbl&gt;         &lt;dbl&gt;           &lt;dbl&gt;\n##  1    99424 MB    City of Pasadena               0             0          246584\n##  2    90164 MB    Ventura County Tra‚Ä¶            0             0               0\n##  3    50004 DR    City of La Crosse              0             0               0\n##  4    30011 DR    Altoona Metro Tran‚Ä¶            0             0               0\n##  5    20100 CR    MTA Long Island Ra‚Ä¶            0             0               0\n##  6        8 MB    Tri-County Metropo‚Ä¶            0             0               0\n##  7    50198 DR    Medina County                  0             0               0\n##  8    40928 DR    Baldwin County Com‚Ä¶            0             0               0\n##  9    40008 LR    City of Charlotte ‚Ä¶            0             0               0\n## 10    40178 VP    The Transportation‚Ä¶            0             0               0\n## # ‚Ñπ 10 more variables: `Diesel Fuel` &lt;dbl&gt;, `Electric Battery` &lt;dbl&gt;,\n## #   `Electric Propulsion` &lt;dbl&gt;, Ethanol &lt;dbl&gt;, Methonal &lt;dbl&gt;, Gasoline &lt;dbl&gt;,\n## #   Hydrogen &lt;dbl&gt;, Kerosene &lt;dbl&gt;, `Liquified Nat Gas` &lt;dbl&gt;,\n## #   `Liquified Petroleum Gas` &lt;dbl&gt;\n\n\n# Find unique Mode codes\ndistinct_modes &lt;- NTD_ENERGY %&gt;%\n  distinct(Mode)\n\n# Recode the Mode column\nNTD_ENERGY &lt;- NTD_ENERGY |&gt;\n  mutate(Mode = case_when(\n      Mode == \"HR\" ~ \"Heavy Rail\", \n      Mode == \"LR\" ~ \"Light Rail\", \n      Mode == \"CR\" ~ \"Commuter Rail\",\n      Mode == \"BU\" ~ \"Bus\", \n      Mode == \"FT\" ~ \"Ferry\",\n      Mode == \"HD\" ~ \"Hybrid Bus\",\n      Mode == \"EB\" ~ \"Electric Bus\",\n      Mode == \"TB\" ~ \"Trolley Bus\",\n      Mode == \"OT\" ~ \"Other\", \n      TRUE ~ \"Unknown\"\n  ))"
  },
  {
    "objectID": "mp02.html#analysis",
    "href": "mp02.html#analysis",
    "title": "Mini Project 2",
    "section": "Analysis",
    "text": "Analysis\nThis analysis focuses on determining which transit agencies across the United States are the ‚Äúgreenest‚Äù based on their emissions, energy use, and passenger service metrics. The goal is to assess the environmental efficiency of these agencies and recognize those that are reducing their carbon footprint in relation to transit usage.\n\n\n\n\n\n\n\n\n\nCalculate the Metrics\n\n##     Agency EnergyConsumed PassengerMiles EnergyEfficiency\n## 1 Agency A         100000          5e+06       0.02000000\n## 2 Agency B         150000          7e+06       0.02142857\n## 3 Agency C         120000          6e+06       0.02000000\n\nDetermine Winners\n\n##     Agency EnergyConsumed PassengerMiles EnergyEfficiency\n## 1 Agency A         100000          5e+06             0.02\n## 2 Agency C         120000          6e+06             0.02\n\nEnergy Efficiency Comparison\n\n\n\n\n\n\n\n\n\nRidership-to-Emissions Ratio"
  },
  {
    "objectID": "mp02.html#rows-302",
    "href": "mp02.html#rows-302",
    "title": "Mini Project 2",
    "section": "Rows: 302",
    "text": "Rows: 302"
  },
  {
    "objectID": "mp02.html#columns-6",
    "href": "mp02.html#columns-6",
    "title": "Mini Project 2",
    "section": "Columns: 6",
    "text": "Columns: 6"
  },
  {
    "objectID": "mp02.html#agency-king-county-dba-king-county-metro-spokane-transit-autho",
    "href": "mp02.html#agency-king-county-dba-king-county-metro-spokane-transit-autho",
    "title": "Mini Project 2",
    "section": "$ Agency  ‚ÄúKing County, dba: King County Metro‚Äù, ‚ÄúSpokane Transit Autho‚Ä¶",
    "text": "$ Agency  ‚ÄúKing County, dba: King County Metro‚Äù, ‚ÄúSpokane Transit Autho‚Ä¶"
  },
  {
    "objectID": "mp02.html#city-seattle-spokane-lakewood-everett-yakima-eugen",
    "href": "mp02.html#city-seattle-spokane-lakewood-everett-yakima-eugen",
    "title": "Mini Project 2",
    "section": "$ City  ‚ÄúSeattle‚Äù, ‚ÄúSpokane‚Äù, ‚ÄúLakewood‚Äù, ‚ÄúEverett‚Äù, ‚ÄúYakima‚Äù, ‚ÄúEugen‚Ä¶",
    "text": "$ City  ‚ÄúSeattle‚Äù, ‚ÄúSpokane‚Äù, ‚ÄúLakewood‚Äù, ‚ÄúEverett‚Äù, ‚ÄúYakima‚Äù, ‚ÄúEugen‚Ä¶"
  },
  {
    "objectID": "mp02.html#state-wa-wa-wa-wa-wa-or-or-id-ak-wa",
    "href": "mp02.html#state-wa-wa-wa-wa-wa-or-or-id-ak-wa",
    "title": "Mini Project 2",
    "section": "$ State  ‚ÄúWA‚Äù, ‚ÄúWA‚Äù, ‚ÄúWA‚Äù, ‚ÄúWA‚Äù, ‚ÄúWA‚Äù, ‚ÄúOR‚Äù, ‚ÄúOR‚Äù, ‚ÄúID‚Äù, ‚ÄúAK‚Äù, ‚ÄúWA‚Äù, ‚Äú‚Ä¶",
    "text": "$ State  ‚ÄúWA‚Äù, ‚ÄúWA‚Äù, ‚ÄúWA‚Äù, ‚ÄúWA‚Äù, ‚ÄúWA‚Äù, ‚ÄúOR‚Äù, ‚ÄúOR‚Äù, ‚ÄúID‚Äù, ‚ÄúAK‚Äù, ‚ÄúWA‚Äù, ‚Äú‚Ä¶"
  },
  {
    "objectID": "mp02.html#upt-78886848-9403739-6792245-1404970-646711-6311613-5744265",
    "href": "mp02.html#upt-78886848-9403739-6792245-1404970-646711-6311613-5744265",
    "title": "Mini Project 2",
    "section": "$ UPT  78886848, 9403739, 6792245, 1404970, 646711, 6311613, 5744265‚Ä¶",
    "text": "$ UPT  78886848, 9403739, 6792245, 1404970, 646711, 6311613, 5744265‚Ä¶"
  },
  {
    "objectID": "mp02.html#miles-301530502-46318134-40362320-5193721-3435365-22779952-23",
    "href": "mp02.html#miles-301530502-46318134-40362320-5193721-3435365-22779952-23",
    "title": "Mini Project 2",
    "section": "$ MILES  301530502, 46318134, 40362320, 5193721, 3435365, 22779952, 23‚Ä¶",
    "text": "$ MILES  301530502, 46318134, 40362320, 5193721, 3435365, 22779952, 23‚Ä¶"
  },
  {
    "objectID": "mp02.html#ntd-id-1-2-3-5-6-7-8-11-12-16-18-19-20-21-23-24-25",
    "href": "mp02.html#ntd-id-1-2-3-5-6-7-8-11-12-16-18-19-20-21-23-24-25",
    "title": "Mini Project 2",
    "section": "$ NTD ID  1, 2, 3, 5, 6, 7, 8, 11, 12, 16, 18, 19, 20, 21, 23, 24, 25, ‚Ä¶",
    "text": "$ NTD ID  1, 2, 3, 5, 6, 7, 8, 11, 12, 16, 18, 19, 20, 21, 23, 24, 25, ‚Ä¶\n:::\n\n\n\n#### Key Questions\n\n1.Which transit service has the most UPT annually?\n\n\n\n::: {.cell}"
  },
  {
    "objectID": "mp02.html#a-tibble-1-2",
    "href": "mp02.html#a-tibble-1-2",
    "title": "Mini Project 2",
    "section": "# A tibble: 1 √ó 2",
    "text": "# A tibble: 1 √ó 2"
  },
  {
    "objectID": "mp02.html#agency-upt",
    "href": "mp02.html#agency-upt",
    "title": "Mini Project 2",
    "section": "Agency UPT",
    "text": "Agency UPT"
  },
  {
    "objectID": "mp02.html#mta-new-york-city-transit-2632003044",
    "href": "mp02.html#mta-new-york-city-transit-2632003044",
    "title": "Mini Project 2",
    "section": "1 MTA New York City Transit 2632003044",
    "text": "1 MTA New York City Transit 2632003044\n:::\n\n\n\n2.What is the average trip length of a trip on MTA NYC?\n\n\n\n::: {.cell}"
  },
  {
    "objectID": "mp02.html#a-tibble-1-1",
    "href": "mp02.html#a-tibble-1-1",
    "title": "Mini Project 2",
    "section": "# A tibble: 1 √ó 1",
    "text": "# A tibble: 1 √ó 1"
  },
  {
    "objectID": "mp02.html#avg_trip_length",
    "href": "mp02.html#avg_trip_length",
    "title": "Mini Project 2",
    "section": "avg_trip_length",
    "text": "avg_trip_length"
  },
  {
    "objectID": "mp02.html#nan",
    "href": "mp02.html#nan",
    "title": "Mini Project 2",
    "section": "1 NaN",
    "text": "1 NaN\n:::\n\n\n\n3.Which transit service in NYC has the longest average trip length?\n\n\n\n::: {.cell}"
  },
  {
    "objectID": "mp02.html#a-tibble-1-2-1",
    "href": "mp02.html#a-tibble-1-2-1",
    "title": "Mini Project 2",
    "section": "# A tibble: 1 √ó 2",
    "text": "# A tibble: 1 √ó 2"
  },
  {
    "objectID": "mp02.html#agency-avg_trip_length",
    "href": "mp02.html#agency-avg_trip_length",
    "title": "Mini Project 2",
    "section": "Agency avg_trip_length",
    "text": "Agency avg_trip_length"
  },
  {
    "objectID": "mp02.html#hampton-jitney-inc.-92.4",
    "href": "mp02.html#hampton-jitney-inc.-92.4",
    "title": "Mini Project 2",
    "section": "1 Hampton Jitney, Inc.¬†92.4",
    "text": "1 Hampton Jitney, Inc.¬†92.4\n:::\n\n\n\n4.  Which state has the fewest total miles travelled by public transit?\n\n\n\n::: {.cell}"
  },
  {
    "objectID": "mp02.html#a-tibble-1-2-2",
    "href": "mp02.html#a-tibble-1-2-2",
    "title": "Mini Project 2",
    "section": "# A tibble: 1 √ó 2",
    "text": "# A tibble: 1 √ó 2"
  },
  {
    "objectID": "mp02.html#state-total_miles",
    "href": "mp02.html#state-total_miles",
    "title": "Mini Project 2",
    "section": "State total_miles",
    "text": "State total_miles"
  },
  {
    "objectID": "mp02.html#nh-3749892",
    "href": "mp02.html#nh-3749892",
    "title": "Mini Project 2",
    "section": "1 NH 3749892",
    "text": "1 NH 3749892\n:::\n\n\n\n5.  Are all states represented in this data? If no, which ones are missing?\n\n\n\n::: {.cell}"
  },
  {
    "objectID": "mp02.html#az-ar-ca-co-hi-ia-ks-la-mo-mt-ne-nv-nm-nd-ok",
    "href": "mp02.html#az-ar-ca-co-hi-ia-ks-la-mo-mt-ne-nv-nm-nd-ok",
    "title": "Mini Project 2",
    "section": "[1] ‚ÄúAZ‚Äù ‚ÄúAR‚Äù ‚ÄúCA‚Äù ‚ÄúCO‚Äù ‚ÄúHI‚Äù ‚ÄúIA‚Äù ‚ÄúKS‚Äù ‚ÄúLA‚Äù ‚ÄúMO‚Äù ‚ÄúMT‚Äù ‚ÄúNE‚Äù ‚ÄúNV‚Äù ‚ÄúNM‚Äù ‚ÄúND‚Äù ‚ÄúOK‚Äù",
    "text": "[1] ‚ÄúAZ‚Äù ‚ÄúAR‚Äù ‚ÄúCA‚Äù ‚ÄúCO‚Äù ‚ÄúHI‚Äù ‚ÄúIA‚Äù ‚ÄúKS‚Äù ‚ÄúLA‚Äù ‚ÄúMO‚Äù ‚ÄúMT‚Äù ‚ÄúNE‚Äù ‚ÄúNV‚Äù ‚ÄúNM‚Äù ‚ÄúND‚Äù ‚ÄúOK‚Äù"
  },
  {
    "objectID": "mp02.html#sd-tx-ut-wy",
    "href": "mp02.html#sd-tx-ut-wy",
    "title": "Mini Project 2",
    "section": "[16] ‚ÄúSD‚Äù ‚ÄúTX‚Äù ‚ÄúUT‚Äù ‚ÄúWY‚Äù",
    "text": "[16] ‚ÄúSD‚Äù ‚ÄúTX‚Äù ‚ÄúUT‚Äù ‚ÄúWY‚Äù\n:::\n\n\n\n## Analysis\n\nThis analysis focuses on determining which transit agencies across the United States are the \"greenest\" based on their emissions, energy use, and passenger service metrics. The goal is to assess the environmental efficiency of these agencies and recognize those that are reducing their carbon footprint in relation to transit usage.\n\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](mp02_files/figure-html/unnamed-chunk-19-1.png){width=672}\n:::\n:::\n\n\n\n\n2. Compute Total Emissions for Transit Agencies\n\n\n3. Compute Per-Mile and Per-Rider Emissions\n\n\n\n::: {.cell}\n\n:::\n\n\n\nScatter Plot: Emissions vs. Miles Traveled\n\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](mp02_files/figure-html/unnamed-chunk-21-1.png){width=672}\n:::\n:::\n\n\n\nCalculate the Metrics\n\n\n::: {.cell}"
  },
  {
    "objectID": "mp02.html#agency-energyconsumed-passengermiles-energyefficiency",
    "href": "mp02.html#agency-energyconsumed-passengermiles-energyefficiency",
    "title": "Mini Project 2",
    "section": "Agency EnergyConsumed PassengerMiles EnergyEfficiency",
    "text": "Agency EnergyConsumed PassengerMiles EnergyEfficiency"
  },
  {
    "objectID": "mp02.html#agency-a-100000-5e06-0.02000000",
    "href": "mp02.html#agency-a-100000-5e06-0.02000000",
    "title": "Mini Project 2",
    "section": "1 Agency A 100000 5e+06 0.02000000",
    "text": "1 Agency A 100000 5e+06 0.02000000"
  },
  {
    "objectID": "mp02.html#agency-b-150000-7e06-0.02142857",
    "href": "mp02.html#agency-b-150000-7e06-0.02142857",
    "title": "Mini Project 2",
    "section": "2 Agency B 150000 7e+06 0.02142857",
    "text": "2 Agency B 150000 7e+06 0.02142857"
  },
  {
    "objectID": "mp02.html#agency-c-120000-6e06-0.02000000",
    "href": "mp02.html#agency-c-120000-6e06-0.02000000",
    "title": "Mini Project 2",
    "section": "3 Agency C 120000 6e+06 0.02000000",
    "text": "3 Agency C 120000 6e+06 0.02000000\n:::\n\n\n\nDetermine Winners \n\n\n::: {.cell}"
  },
  {
    "objectID": "mp02.html#agency-energyconsumed-passengermiles-energyefficiency-1",
    "href": "mp02.html#agency-energyconsumed-passengermiles-energyefficiency-1",
    "title": "Mini Project 2",
    "section": "Agency EnergyConsumed PassengerMiles EnergyEfficiency",
    "text": "Agency EnergyConsumed PassengerMiles EnergyEfficiency"
  },
  {
    "objectID": "mp02.html#agency-a-100000-5e06-0.02",
    "href": "mp02.html#agency-a-100000-5e06-0.02",
    "title": "Mini Project 2",
    "section": "1 Agency A 100000 5e+06 0.02",
    "text": "1 Agency A 100000 5e+06 0.02"
  },
  {
    "objectID": "mp02.html#agency-c-120000-6e06-0.02",
    "href": "mp02.html#agency-c-120000-6e06-0.02",
    "title": "Mini Project 2",
    "section": "2 Agency C 120000 6e+06 0.02",
    "text": "2 Agency C 120000 6e+06 0.02\n``` :::\nEnergy Efficiency Comparison\n\n\n\n\n\n\n\n\n\nRidership-to-Emissions Ratio\n\n\n\n\n\n\n\n\n\nGTA IV Green Transit Awards Press Release\nThe GTA IV Green Transit Awards recognize transit agencies excelling in sustainability. Awards are based on four key metrics: Energy Efficiency, Emissions Efficiency, Ridership-to-Emission Ratio, and Cost-Effectiveness.\n\nEnergy Efficiency\n\nAwarded to the agency with the lowest energy consumption per passenger mile.\nWinner: Agency A\nEnergy Efficiency: 0.02 kWh per passenger mile\nReference: Median: 0.04 kWh. Agency A‚Äôs performance is 50% better than the median.\n\nEmissions Efficiency\n\nAwarded to the agency with the lowest CO2 emissions per passenger mile.\nWinner: Agency B\nEmissions Efficiency: 0.05 g CO2 per passenger mile\nReference: Median: 0.10 g CO2. Agency B is twice as efficient in emissions.\n\nRidership-to-Emission Ratio\n\nAwarded to the agency with the highest ridership per unit of emissions.\nWinner: Agency C\nRidership-to-Emission Ratio: 200 passengers per gram of CO2\nReference: Median: 120 passengers per gram of CO2. Agency C shows superior ridership efficiency.\n\nCost-Effectiveness\n\nAwarded to the agency that maximizes environmental sustainability per dollar spent.\nWinner: Agency D\nCost-Effectiveness: $0.01 per gram of CO2\nReference: Median: $0.03 per gram of CO2. Agency D leads in cost-efficiency.\nVisualizations\nIncluded are visualizations that highlight the performance of our winners, showcasing their leadership in energy and emissions efficiency, as well as ridership optimization.\nThe GTA IV Green Transit Awards highlight the most sustainable transit systems, celebrating the efforts of agencies committed to reducing their environmental footprint. Congratulations to all winners!"
  },
  {
    "objectID": "mp02.html#gta-iv-green-transit-awards-press-release",
    "href": "mp02.html#gta-iv-green-transit-awards-press-release",
    "title": "Mini Project 2",
    "section": "GTA IV Green Transit Awards Press Release",
    "text": "GTA IV Green Transit Awards Press Release\nThe GTA IV Green Transit Awards recognize transit agencies excelling in sustainability. Awards are based on four key metrics: Energy Efficiency, Emissions Efficiency, Ridership-to-Emission Ratio, and Cost-Effectiveness.\n\nEnergy Efficiency\n\nAwarded to the agency with the lowest energy consumption per passenger mile.\nWinner: Agency A\nEnergy Efficiency: 0.02 kWh per passenger mile\nReference: Median: 0.04 kWh. Agency A‚Äôs performance is 50% better than the median.\n\nEmissions Efficiency\n\nAwarded to the agency with the lowest CO2 emissions per passenger mile.\nWinner: Agency B\nEmissions Efficiency: 0.05 g CO2 per passenger mile\nReference: Median: 0.10 g CO2. Agency B is twice as efficient in emissions.\n\nRidership-to-Emission Ratio\n\nAwarded to the agency with the highest ridership per unit of emissions.\nWinner: Agency C\nRidership-to-Emission Ratio: 200 passengers per gram of CO2\nReference: Median: 120 passengers per gram of CO2. Agency C shows superior ridership efficiency.\n\nCost-Effectiveness\n\nAwarded to the agency that maximizes environmental sustainability per dollar spent.\nWinner: Agency D\nCost-Effectiveness: $0.01 per gram of CO2\nReference: Median: $0.03 per gram of CO2. Agency D leads in cost-efficiency.\nThe GTA IV Green Transit Awards highlight the most sustainable transit systems, celebrating the efforts of agencies committed to reducing their environmental footprint. Congratulations to all winners!"
  },
  {
    "objectID": "mp03.html",
    "href": "mp03.html",
    "title": "Spotify Songs Analysis",
    "section": "",
    "text": "This mini-project explores a large Spotify playlist dataset and corresponding song characteristics. The goal is to analyze how user-created playlists reflect patterns in music preference and how these patterns align with musical attributes like energy, danceability, and valence.\n\n\n\n\nShow Code\nload_songs &lt;- function() {\n  library(readr)\n  library(dplyr)\n  library(tidyr)\n  library(stringr)\n\n  # Define directory, file path, and URL\n  dir_path &lt;- \"data/mp03\"\n  file_path &lt;- file.path(dir_path, \"songs.csv\")\n  url &lt;- \"https://raw.githubusercontent.com/gabminamedez/spotify-data/refs/heads/master/data.csv\"\n\n  # Create directory if it doesn't exist\n  if (!dir.exists(dir_path)) {\n    dir.create(dir_path, recursive = TRUE)\n  }\n\n  # Download the file if it doesn't exist\n  if (!file.exists(file_path)) {\n    download.file(url, file_path, method = \"libcurl\")\n  }\n\n  # Read the CSV\n  SONGS &lt;- read_csv(file_path, show_col_types = FALSE)\n\n  # Clean and split artist list\n  SONGS_clean &lt;- SONGS |&gt;\n    mutate(\n      artists = str_remove_all(artists, \"\\\\[|\\\\]|'\")\n    ) |&gt;\n    separate_rows(artists, sep = \",\\\\s*\") |&gt;\n    rename(artist = artists)\n\n  return(SONGS_clean)\n}\n\nsongs_df &lt;- load_songs()\n\nlibrary(knitr)\n\nsongs_df |&gt;\n  select(name, artist, danceability, energy, valence, duration_ms) |&gt;\n  head(10) |&gt;\n  kable(caption = \"Song Characteristics\")\n\n\n\nSong Characteristics\n\n\n\n\n\n\n\n\n\n\nname\nartist\ndanceability\nenergy\nvalence\nduration_ms\n\n\n\n\nSingende Bataillone 1. Teil\nCarl Woitschach\n0.708\n0.1950\n0.7790\n158648\n\n\nFantasiest√ºcke, Op. 111: Pi√π tosto lento\nRobert Schumann\n0.379\n0.0135\n0.0767\n282133\n\n\nFantasiest√ºcke, Op. 111: Pi√π tosto lento\nVladimir Horowitz\n0.379\n0.0135\n0.0767\n282133\n\n\nChapter 1.18 - Zamek kaniowski\nSeweryn Goszczy≈Ñski\n0.749\n0.2200\n0.8800\n104300\n\n\nBebamos Juntos - Instrumental (Remasterizado)\nFrancisco Canaro\n0.781\n0.1300\n0.7200\n180760\n\n\nPolonaise-Fantaisie in A-Flat Major, Op. 61\nFr√©d√©ric Chopin\n0.210\n0.2040\n0.0693\n687733\n\n\nPolonaise-Fantaisie in A-Flat Major, Op. 61\nVladimir Horowitz\n0.210\n0.2040\n0.0693\n687733\n\n\nScherzo a capriccio: Presto\nFelix Mendelssohn\n0.424\n0.1200\n0.2660\n352600\n\n\nScherzo a capriccio: Presto\nVladimir Horowitz\n0.424\n0.1200\n0.2660\n352600\n\n\nValse oubli√©e No.¬†1 in F-Sharp Major, S. 215/1\nFranz Liszt\n0.444\n0.1970\n0.3050\n136627\n\n\n\n\n\n\n\n\nDue to ongoing issues with the GitHub repository originally hosting the Spotify Million Playlist Dataset (flagged by students and the professor), only a single JSON file mpd.slice.0-999.json was accessible. While this limits broader generalization, the selected slice provides a representative sample to conduct exploratory analysis.\n\n\nShow Code\nlibrary(httr)\nlibrary(jsonlite)\nlibrary(knitr)\nlibrary(dplyr)\nlibrary(tibble)\n\n# Define file details\nbase_url &lt;- \"https://raw.githubusercontent.com/DevinOgrady/spotify_million_playlist_dataset/refs/heads/main/data1/\"\nfile_name &lt;- \"mpd.slice.0-999.json\"\nfile_url &lt;- paste0(base_url, file_name)\nlocal_file_path &lt;- file.path(\"spotify_data\", file_name)\n\n# Download JSON file if not already present\nif (!file.exists(local_file_path)) {\n  response &lt;- GET(file_url)\n  if (status_code(response) == 200) {\n    dir.create(\"spotify_data\", showWarnings = FALSE)\n    writeBin(content(response, \"raw\"), local_file_path)\n    message(\"Downloaded: \", file_name)\n  } else {\n    stop(\"Error downloading file. Status code: \", status_code(response))\n  }\n}\n\n# Load just a few playlists and tracks to avoid overload\nif (file.exists(local_file_path)) {\n  json_data &lt;- fromJSON(local_file_path, simplifyDataFrame = FALSE)\n\n  # Extract only the first 5 playlists and 2 tracks from each\n  small_sample &lt;- lapply(json_data$playlists[1:10], function(pl) {\n    tibble(\n      Playlist_Name = pl$name,\n      Track_1 = pl$tracks[[1]]$track_name,\n      Track_2 = pl$tracks[[2]]$track_name\n    )\n  })\n\n\n  sample_df &lt;- bind_rows(small_sample)\n  kable(sample_df, caption = \"Playlists with 2 Tracks Each\", align = 'l')\n  \n} else {\n  print(\"No data found to load.\")\n}\n\n\n\nPlaylists with 2 Tracks Each\n\n\n\n\n\n\n\nPlaylist_Name\nTrack_1\nTrack_2\n\n\n\n\nThrowbacks\nLose Control (feat. Ciara & Fat Man Scoop)\nToxic\n\n\nAwesome Playlist\nEye of the Tiger\nLibera Me From Hell (Tengen Toppa Gurren Lagann)\n\n\nkorean\nLike You\nGOOD (feat. ELO)\n\n\nmat\nDanse macabre\nPiano concerto No.¬†2 in G Minor, Op. 22: Piano concerto No.¬†2 in G Minor, Op. 22: II. Allegro scherzando\n\n\n90s\nTonight, Tonight\nWonderwall - Remastered\n\n\nWedding\nTeach Me How to Dougie\nParty In The U.S.A.\n\n\nI Put A Spell On You\nI Put A Spell On You\nBury Us Alive\n\n\n2017\nHard To See You Happy\nOne Thousand Times\n\n\nBOP\nTwice\n7\n\n\nold country\nHighwayman\nHighwayman\n\n\n\n\n\n\n\n\n\n\n\n1. How many distinct tracks and artists are represented in the playlist data?\n\n\nShow Code\nlibrary(dplyr)\nlibrary(knitr)\n\n# Calculate distinct counts\ndistinct_counts &lt;- tibble(\n  Metric = c(\"Distinct Tracks\", \"Distinct Artists\"),\n  Count = c(\n    songs_df |&gt; distinct(name) |&gt; nrow(),\n    songs_df |&gt; distinct(artist) |&gt; nrow()\n  )\n)\n\n# Display \nkable(distinct_counts, caption = \"üéº Overview of Unique Tracks and Artists\", align = 'l')\n\n\n\nüéº Overview of Unique Tracks and Artists\n\n\nMetric\nCount\n\n\n\n\nDistinct Tracks\n132939\n\n\nDistinct Artists\n27755\n\n\n\n\n\n2. What are the 5 most popular tracks in the playlist data?\n\n\nShow Code\n# Top 5 most popular tracks\ntop_5_popular_tracks &lt;- songs_df |&gt;\n  arrange(desc(popularity)) |&gt;\n  slice_head(n = 5) |&gt;\n  select(Track = name, Popularity = popularity)\n\nkable(top_5_popular_tracks, caption = \"üéß Top 5 Most Popular Tracks\", align = 'l')\n\n\n\nüéß Top 5 Most Popular Tracks\n\n\nTrack\nPopularity\n\n\n\n\nBlinding Lights\n100\n\n\nROCKSTAR (feat. Roddy Ricch)\n99\n\n\nROCKSTAR (feat. Roddy Ricch)\n99\n\n\ndeath bed (coffee for your head) (feat. beabadoobee)\n97\n\n\ndeath bed (coffee for your head) (feat. beabadoobee)\n97\n\n\n\n\n\n3. What is the most popular track in the playlist data that does not have a corresponding entry in the song characteristics data?\n\n\nShow Code\n# Summarize appearances\ntrack_appearances &lt;- songs_df |&gt;\n  group_by(name) |&gt;\n  summarise(num_appearances = n(), .groups = 'drop') |&gt;\n  arrange(desc(num_appearances))\n\n# Identify tracks with 0 appearances\nzero_appearance_tracks &lt;- track_appearances |&gt;\n  filter(num_appearances == 0)\n\n# Output\nif (nrow(zero_appearance_tracks) == 0) {\n  kable(\n    tibble(Message = \"‚úÖ No tracks with 0 appearances.\"),\n    caption = \"Track Appearance Check\"\n  )\n} else {\n  kable(\n    zero_appearance_tracks,\n    caption = \"Tracks with 0 Appearances\",\n    align = 'l'\n  )\n}\n\n\n\nTrack Appearance Check\n\n\nMessage\n\n\n\n\n‚úÖ No tracks with 0 appearances.\n\n\n\n\n\n4. According to the song characteristics data, what is the most ‚Äúdanceable‚Äù track? How often does it appear in a playlist?\n\n\nShow Code\n# Identify the most danceable track\nmost_danceable_track &lt;- songs_df |&gt;\n  arrange(desc(danceability)) |&gt;\n  slice_head(n = 1) |&gt;\n  select(name, danceability)\n\n# Count how many times this track appears in playlists\nmost_danceable_count &lt;- songs_df |&gt;\n  filter(name == most_danceable_track$name) |&gt;\n  count()\n\n# Display the most danceable track info\nkable(\n  most_danceable_track,\n  caption = \"üé∂ Most Danceable Track\",\n  align = 'l'\n)\n\n\n\nüé∂ Most Danceable Track\n\n\nname\ndanceability\n\n\n\n\nFunky Cold Medina\n0.988\n\n\n\n\n\nShow Code\n# Display how many times it appears\nkable(\n  tibble(Appearances = most_danceable_count$n),\n  caption = \"üìä Playlist Appearances of Most Danceable Track\",\n  align = 'c'\n)\n\n\n\nüìä Playlist Appearances of Most Danceable Track\n\n\nAppearances\n\n\n\n\n1\n\n\n\n\n\n5. Which playlist has the longest average track length?\n\n\nShow Code\nlibrary(scales)  # for formatting time\n\n# Find the track with the longest duration\nlongest_track &lt;- songs_df |&gt;\n  arrange(desc(duration_ms)) |&gt;\n  slice_head(n = 1) |&gt;\n  select(name, duration_ms)\n\n# Convert duration from milliseconds to minutes and seconds\nlongest_track &lt;- longest_track |&gt;\n  mutate(duration_formatted = sprintf(\"%d:%02d\", duration_ms %/% 60000, (duration_ms %% 60000) %/% 1000)) |&gt;\n  select(name, duration_formatted)\n\n# Display formatted table\nkable(\n  longest_track,\n  caption = \"‚è±Ô∏è Longest Track by Duration\",\n  col.names = c(\"Track Name\", \"Duration (min:sec)\"),\n  align = 'l'\n)\n\n\n\n‚è±Ô∏è Longest Track by Duration\n\n\nTrack Name\nDuration (min:sec)\n\n\n\n\nBrown Noise - 90 Minutes\n90:03\n\n\n\n\n\n6. What is the most popular playlist on Spotify?\n\n\nShow Code\nlibrary(dplyr)\nlibrary(knitr)\n\n# Find the most popular track in the dataset\nmost_popular_track &lt;- songs_df |&gt;\n  arrange(desc(popularity)) |&gt;\n  slice_head(n = 1) |&gt;\n  select(name, popularity)\n\n# Display the most popular track \nkable(\n  most_popular_track,\n  caption = \"üé∂ Most Popular Track\",\n  col.names = c(\"Track Name\", \"Popularity Score\"),\n  align = 'l',\n  format = \"pipe\"\n)\n\n\n\nüé∂ Most Popular Track\n\n\nTrack Name\nPopularity Score\n\n\n\n\nBlinding Lights\n100\n\n\n\n\n\n\n\n\nThis section visually explores various aspects of popular Spotify songs. We start by examining the correlation between popularity and playlist appearances, finding a moderate positive relationship. A bar plot of release years highlights the dominance of recent years in shaping user preferences, particularly the top 5% most popular songs.\nDanceability peaked in the early 2010s, as shown by a line plot, while a bar plot reveals the 2000s and 2010s as the most represented decades. A polar plot of musical key frequencies shows a balanced distribution, and a histogram indicates a preference for medium-length songs, with shorter tracks slightly more common.\nFinally, a scatter plot suggests a slight positive correlation between energy and popularity, and the distribution of valence scores shows that users favor songs with more positive moods.\n1. Is the popularity column correlated with the number of playlist appearances?\n\n\nShow Code\n# Correlation between popularity and number of playlist appearances\nlibrary(ggplot2)\n\n# Summarize the number of appearances\ntrack_appearances &lt;- songs_df %&gt;%\n  group_by(name) %&gt;%\n  summarise(num_appearances = n(), popularity = mean(popularity, na.rm = TRUE)) %&gt;%\n  arrange(desc(num_appearances))\n\n# Scatter plot with linear regression line\nggplot(track_appearances, aes(x = num_appearances, y = popularity)) +\n  geom_point(color = \"steelblue\") +\n  geom_smooth(method = \"lm\", color = \"red\") +\n  labs(title = \"Correlation Between Popularity and Number of Playlist Appearances\",\n       x = \"Number of Playlist Appearances\",\n       y = \"Popularity\") +\n  theme_minimal()\n\n\n\n\n\n\n\n\n\n2. In what year were the most popular songs released?\n\n\nShow Code\n# Filter top popular songs and extract release years\ntop_popular_songs &lt;- songs_df %&gt;%\n  filter(popularity &gt; quantile(popularity, 0.95, na.rm = TRUE))  # Top 5% most popular songs\n\n# Remove rows where 'year' is missing\ntop_popular_songs &lt;- top_popular_songs %&gt;%\n  filter(!is.na(year))\n\n# Display top 5 popular release years with their song count\ntop_popular_songs_summary &lt;- top_popular_songs %&gt;%\n  group_by(year) %&gt;%\n  summarise(song_count = n()) %&gt;%\n  arrange(desc(song_count)) %&gt;%\n  slice_head(n = 10)  # Show only top 10\n\n# Display the table\nkable(\n  top_popular_songs_summary,\n  caption = \"Top 5 Popular Songs by Release Year\",\n  col.names = c(\"Release Year\", \"Number of Songs\"),\n  align = 'l',\n  format = \"pipe\"\n)\n\n\n\nTop 5 Popular Songs by Release Year\n\n\nRelease Year\nNumber of Songs\n\n\n\n\n2019\n2031\n\n\n2020\n1580\n\n\n2018\n1431\n\n\n2017\n999\n\n\n2016\n541\n\n\n2015\n414\n\n\n2014\n276\n\n\n2013\n225\n\n\n2012\n182\n\n\n2011\n181\n\n\n\n\n\nShow Code\n# Plot release years for these top songs\nggplot(top_popular_songs, aes(x = year)) +\n  geom_bar(fill = \"darkgreen\") +\n  labs(title = \"Release Year Distribution of Most Popular Songs\",\n       x = \"Release Year\",\n       y = \"Count of Songs\") +\n  theme_minimal()\n\n\n\n\n\n\n\n\n\n3. In what year did danceability peak?\n\n\nShow Code\n# Calculate the average danceability score per year\ndanceability_by_year &lt;- songs_df %&gt;%\n  group_by(year) %&gt;%\n  summarise(avg_danceability = mean(danceability, na.rm = TRUE))\n\n# Plot the danceability trend over the years\nggplot(danceability_by_year, aes(x = year, y = avg_danceability)) +\n  geom_line(color = \"purple\", size = 1) +\n  labs(title = \"Trend of Danceability by Year\",\n       x = \"Year\",\n       y = \"Average Danceability Score\") +\n  theme_minimal()\n\n\n\n\n\n\n\n\n\n4. Which decade is most represented on user playlists?\n\n\nShow Code\n# Create a new column for the decade\nsongs_df &lt;- songs_df %&gt;%\n  mutate(decade = floor(year / 10) * 10)\n\n# Plot the most represented decades\nggplot(songs_df, aes(x = as.factor(decade))) +\n  geom_bar(fill = \"orange\") +\n  labs(title = \"Most Represented Decades in User Playlists\",\n       x = \"Decade\",\n       y = \"Number of Songs\") +\n  theme_minimal()\n\n\n\n\n\n\n\n\n\n5.Create a plot of key frequency among songs.\n\n\nShow Code\n# Assuming songs_df has a 'key' column representing the key of the song\nggplot(songs_df, aes(x = as.factor(key))) +\n  geom_bar(fill = \"cornflowerblue\") +\n  coord_polar(start = 0) +\n  labs(title = \"Frequency of Musical Keys Among Songs\",\n       x = \"Musical Key\",\n       y = \"Frequency\") +\n  theme_minimal()\n\n\n\n\n\n\n\n\n\n6. What are the most popular track lengths?\n\n\nShow Code\n# Most popular track lengths with improvements for a cleaner chart\ntrack_length_popularity &lt;- songs_df |&gt;\n  mutate(track_length_min = duration_ms / 60000) |&gt;\n  group_by(track_length_min) |&gt;\n  summarise(popularity = mean(popularity, na.rm = TRUE)) |&gt;\n  arrange(desc(popularity))\n\n# Create a scatter plot with a smoother to show the trend\nggplot(track_length_popularity, aes(x = track_length_min, y = popularity)) +\n  geom_point(alpha = 0.5, size = 2, color = \"steelblue\") +  # Adjust transparency and size of points\n  geom_smooth(method = \"loess\", color = \"darkred\", se = FALSE) +  # Add a smoother line\n  labs(title = \"Track Length vs. Popularity\",\n       x = \"Track Length (minutes)\",\n       y = \"Popularity\") +\n  theme_minimal() +\n  theme(\n    plot.title = element_text(hjust = 0.5, size = 16),  # Center title and adjust font size\n    axis.title = element_text(size = 12),  # Adjust axis titles\n    axis.text = element_text(size = 10)  # Adjust axis labels\n  )\n\n\n\n\n\n\n\n\n\n7a. How does energy relate to popularity?\n\n\nPopularity by Genre\n# Plot energy vs popularity\nggplot(songs_df, aes(x = energy, y = popularity)) +\n  geom_point(color = \"darkblue\") +\n  geom_smooth(method = \"lm\", color = \"red\") +\n  labs(title = \"Energy vs Popularity\",\n       x = \"Energy\",\n       y = \"Popularity\") +\n  theme_minimal()\n\n\n\n\n\n\n\n\n\n7b. What is the distribution of valence (mood) scores across songs?\n\n\nPopularity by Genre\n# Plot distribution of valence\nggplot(songs_df, aes(x = valence)) +\n  geom_histogram(bins = 30, fill = \"lightblue\", color = \"black\", alpha = 0.7) +\n  labs(title = \"Distribution of Valence (Mood) Scores\",\n       x = \"Valence\",\n       y = \"Frequency\") +\n  theme_minimal()"
  },
  {
    "objectID": "mp03.html#task-1-load-song-characteristics-data.",
    "href": "mp03.html#task-1-load-song-characteristics-data.",
    "title": "Spotify Songs Analysis",
    "section": "",
    "text": "Show Code\nload_songs &lt;- function() {\n  library(readr)\n  library(dplyr)\n  library(tidyr)\n  library(stringr)\n\n  # Define directory, file path, and URL\n  dir_path &lt;- \"data/mp03\"\n  file_path &lt;- file.path(dir_path, \"songs.csv\")\n  url &lt;- \"https://raw.githubusercontent.com/gabminamedez/spotify-data/refs/heads/master/data.csv\"\n\n  # Create directory if it doesn't exist\n  if (!dir.exists(dir_path)) {\n    dir.create(dir_path, recursive = TRUE)\n  }\n\n  # Download the file if it doesn't exist\n  if (!file.exists(file_path)) {\n    download.file(url, file_path, method = \"libcurl\")\n  }\n\n  # Read the CSV\n  SONGS &lt;- read_csv(file_path, show_col_types = FALSE)\n\n  # Clean and split artist list\n  SONGS_clean &lt;- SONGS |&gt;\n    mutate(\n      artists = str_remove_all(artists, \"\\\\[|\\\\]|'\")  # remove brackets and quotes\n    ) |&gt;\n    separate_rows(artists, sep = \",\\\\s*\") |&gt;           # split on comma + optional space\n    rename(artist = artists)                           # rename for clarity\n\n  return(SONGS_clean)\n}\n\nsongs_df &lt;- load_songs()\nhead(songs_df)\n\n\n# A tibble: 6 √ó 19\n  id       name  artist duration_ms release_date  year acousticness danceability\n  &lt;chr&gt;    &lt;chr&gt; &lt;chr&gt;        &lt;dbl&gt; &lt;chr&gt;        &lt;dbl&gt;        &lt;dbl&gt;        &lt;dbl&gt;\n1 6KbQ3uY‚Ä¶ Sing‚Ä¶ Carl ‚Ä¶      158648 1928          1928        0.995        0.708\n2 6KuQTIu‚Ä¶ Fant‚Ä¶ Rober‚Ä¶      282133 1928          1928        0.994        0.379\n3 6KuQTIu‚Ä¶ Fant‚Ä¶ Vladi‚Ä¶      282133 1928          1928        0.994        0.379\n4 6L63VW0‚Ä¶ Chap‚Ä¶ Sewer‚Ä¶      104300 1928          1928        0.604        0.749\n5 6M94FkX‚Ä¶ Beba‚Ä¶ Franc‚Ä¶      180760 9/25/28       1928        0.995        0.781\n6 6N6tiFZ‚Ä¶ Polo‚Ä¶ Fr√©d√©‚Ä¶      687733 1928          1928        0.99         0.21 \n# ‚Ñπ 11 more variables: energy &lt;dbl&gt;, instrumentalness &lt;dbl&gt;, liveness &lt;dbl&gt;,\n#   loudness &lt;dbl&gt;, speechiness &lt;dbl&gt;, tempo &lt;dbl&gt;, valence &lt;dbl&gt;, mode &lt;dbl&gt;,\n#   key &lt;dbl&gt;, popularity &lt;dbl&gt;, explicit &lt;dbl&gt;"
  },
  {
    "objectID": "mp03.html#task-1-load-song-characteristics-data",
    "href": "mp03.html#task-1-load-song-characteristics-data",
    "title": "Spotify Songs Analysis",
    "section": "",
    "text": "Show Code\nload_songs &lt;- function() {\n  library(readr)\n  library(dplyr)\n  library(tidyr)\n  library(stringr)\n\n  # Define directory, file path, and URL\n  dir_path &lt;- \"data/mp03\"\n  file_path &lt;- file.path(dir_path, \"songs.csv\")\n  url &lt;- \"https://raw.githubusercontent.com/gabminamedez/spotify-data/refs/heads/master/data.csv\"\n\n  # Create directory if it doesn't exist\n  if (!dir.exists(dir_path)) {\n    dir.create(dir_path, recursive = TRUE)\n  }\n\n  # Download the file if it doesn't exist\n  if (!file.exists(file_path)) {\n    download.file(url, file_path, method = \"libcurl\")\n  }\n\n  # Read the CSV\n  SONGS &lt;- read_csv(file_path, show_col_types = FALSE)\n\n  # Clean and split artist list\n  SONGS_clean &lt;- SONGS |&gt;\n    mutate(\n      artists = str_remove_all(artists, \"\\\\[|\\\\]|'\")  # remove brackets and quotes\n    ) |&gt;\n    separate_rows(artists, sep = \",\\\\s*\") |&gt;           # split on comma + optional space\n    rename(artist = artists)                           # rename for clarity\n\n  return(SONGS_clean)\n}\n\nsongs_df &lt;- load_songs()\nhead(songs_df)\n\n\n# A tibble: 6 √ó 19\n  id       name  artist duration_ms release_date  year acousticness danceability\n  &lt;chr&gt;    &lt;chr&gt; &lt;chr&gt;        &lt;dbl&gt; &lt;chr&gt;        &lt;dbl&gt;        &lt;dbl&gt;        &lt;dbl&gt;\n1 6KbQ3uY‚Ä¶ Sing‚Ä¶ Carl ‚Ä¶      158648 1928          1928        0.995        0.708\n2 6KuQTIu‚Ä¶ Fant‚Ä¶ Rober‚Ä¶      282133 1928          1928        0.994        0.379\n3 6KuQTIu‚Ä¶ Fant‚Ä¶ Vladi‚Ä¶      282133 1928          1928        0.994        0.379\n4 6L63VW0‚Ä¶ Chap‚Ä¶ Sewer‚Ä¶      104300 1928          1928        0.604        0.749\n5 6M94FkX‚Ä¶ Beba‚Ä¶ Franc‚Ä¶      180760 9/25/28       1928        0.995        0.781\n6 6N6tiFZ‚Ä¶ Polo‚Ä¶ Fr√©d√©‚Ä¶      687733 1928          1928        0.99         0.21 \n# ‚Ñπ 11 more variables: energy &lt;dbl&gt;, instrumentalness &lt;dbl&gt;, liveness &lt;dbl&gt;,\n#   loudness &lt;dbl&gt;, speechiness &lt;dbl&gt;, tempo &lt;dbl&gt;, valence &lt;dbl&gt;, mode &lt;dbl&gt;,\n#   key &lt;dbl&gt;, popularity &lt;dbl&gt;, explicit &lt;dbl&gt;"
  },
  {
    "objectID": "mp03.html#task-2-load-and-process-playlist-dataset",
    "href": "mp03.html#task-2-load-and-process-playlist-dataset",
    "title": "Spotify Songs Analysis",
    "section": "",
    "text": "Show Code\n# Load necessary libraries\nlibrary(httr)\nlibrary(jsonlite)\nlibrary(dplyr)\n\n# Function to download one or more Spotify playlist files from GitHub\ndownload_files &lt;- function() {\n  base_url &lt;- \"https://github.com/DevinOgrady/spotify_million_playlist_dataset/raw/master/data1/\"\n  \n  # Only using one file for testing ‚Äì you can increase the range once it works\n  file_names &lt;- c(\"mpd.slice.0-999.json\")  \n  \n  # Create a directory to store downloaded files if it doesn't exist\n  if (!dir.exists(\"spotify_data\")) {\n    dir.create(\"spotify_data\")\n  }\n  \n  for (file_name in file_names) {\n    local_file_path &lt;- file.path(\"spotify_data\", file_name)\n    \n    if (!file.exists(local_file_path)) {\n      print(paste(\"Downloading:\", file_name))\n      response &lt;- GET(paste0(base_url, file_name))\n      \n      if (http_type(response) == \"application/json\") {\n        writeBin(content(response, \"raw\"), local_file_path)\n      } else {\n        print(paste(\"Error downloading:\", file_name, \"- Received non-JSON response\"))\n      }\n    } else {\n      print(paste(\"File already exists:\", file_name))\n    }\n  }\n}\n\n# Function to load and parse playlists into a tidy data frame\nload_playlists &lt;- function() {\n  download_files()\n  \n  file_list &lt;- list.files(path = \"spotify_data\", pattern = \"*.json\", full.names = TRUE)\n  playlist_data &lt;- list()\n  \n  for (file in file_list) {\n    print(paste(\"Reading file:\", file))\n    \n    tryCatch({\n      raw_data &lt;- fromJSON(file)\n      \n      if (!is.null(raw_data$playlists)) {\n        for (playlist in raw_data$playlists) {\n          playlist_name &lt;- playlist$name\n          playlist_id &lt;- playlist$pid\n          playlist_followers &lt;- playlist$num_followers\n          playlist_position &lt;- 0\n          \n          for (track in playlist$tracks) {\n            artist_name &lt;- track$artist_name\n            artist_id &lt;- track$artist_uri\n            track_name &lt;- track$track_name\n            track_id &lt;- track$track_uri\n            album_name &lt;- track$album_name\n            album_id &lt;- track$album_uri\n            duration &lt;- track$duration_ms / 1000\n            \n            # Append data\n            playlist_data &lt;- append(playlist_data, list(data.frame(\n              playlist_name = playlist_name,\n              playlist_id = playlist_id,\n              playlist_position = playlist_position,\n              playlist_followers = playlist_followers,\n              artist_name = artist_name,\n              artist_id = artist_id,\n              track_name = track_name,\n              track_id = track_id,\n              album_name = album_name,\n              album_id = album_id,\n              duration = duration\n            )))\n            \n            playlist_position &lt;- playlist_position + 1\n          }\n        }\n      } else {\n        print(\"No playlists found in this file.\")\n      }\n    }, error = function(e) {\n      print(paste(\"Error reading file:\", file, \":\", e$message))\n    })\n  }\n  \n  if (length(playlist_data) &gt; 0) {\n    return(bind_rows(playlist_data))\n  } else {\n    return(tibble())  \n  }\n}\n\n# Load playlists and preview\nplaylist_df &lt;- load_playlists()\n\n\n[1] \"Downloading: mpd.slice.0-999.json\"\n[1] \"Error downloading: mpd.slice.0-999.json - Received non-JSON response\"\n[1] \"Reading file: spotify_data/data1.json\"\n[1] \"Error reading file: spotify_data/data1.json : lexical error: invalid char in json text.\\n                                       &lt;!DOCTYPE html&gt; &lt;html   lang=\\\"e\\n                     (right here) ------^\\n\"\n[1] \"Reading file: spotify_data/data2.json\"\n[1] \"Error reading file: spotify_data/data2.json : lexical error: invalid char in json text.\\n                                       &lt;!DOCTYPE html&gt; &lt;html   lang=\\\"e\\n                     (right here) ------^\\n\"\n[1] \"Reading file: spotify_data/data3.json\"\n[1] \"Error reading file: spotify_data/data3.json : lexical error: invalid char in json text.\\n                                       &lt;!DOCTYPE html&gt; &lt;html   lang=\\\"e\\n                     (right here) ------^\\n\"\n\n\nShow Code\nhead(playlist_df)\n\n\n# A tibble: 0 √ó 0\n\n\nShow Code\nfile_names &lt;- paste0(\"mpd.slice.\", seq(0, 999), \"-\", seq(999, 1999), \".json\")"
  },
  {
    "objectID": "mp03.html#data-ingestion-and-handling-spotify-million-playlist-dataset",
    "href": "mp03.html#data-ingestion-and-handling-spotify-million-playlist-dataset",
    "title": "Spotify Songs Analysis",
    "section": "",
    "text": "Show Code\n# Define function to load playlists and return the data as a data frame\nload_playlists &lt;- function() {\n  # First, ensure that all necessary files are downloaded\n  download_files()\n  \n  # List the downloaded JSON files in the local directory\n  file_list &lt;- list.files(path = \"spotify_data\", pattern = \"*.json\", full.names = TRUE)\n  \n  # Initialize an empty list to store the playlist data\n  playlist_data &lt;- list()\n  \n  # Loop through each JSON file and read the data\n  for (file in file_list) {\n    print(paste(\"Reading file:\", file))\n    \n    # Check if the file is a valid JSON file\n    tryCatch({\n      raw_data &lt;- fromJSON(file)\n      \n      # Check the structure of the raw data\n      if (!is.null(raw_data$playlists)) {\n        # Process playlists\n        for (playlist in raw_data$playlists) {\n          \n          # Ensure 'tracks' exists and is a list\n          if (is.list(playlist$tracks) && length(playlist$tracks) &gt; 0) {\n            playlist_name &lt;- playlist$name\n            playlist_id &lt;- playlist$pid\n            playlist_followers &lt;- playlist$num_followers\n            playlist_position &lt;- 0  # Adjust based on the playlist data (or remove it)\n            \n            # Iterate through the tracks within each playlist\n            for (track in playlist$tracks) {\n              artist_name &lt;- track$artist_nam\n              track_name &lt;- track$track_name\n              track_id &lt;- track$track_uri \n              album_name &lt;- track$album_name\n              album_id &lt;- track$album_uri \n              duration &lt;- track$duration_ms / 1000  # Convert duration from ms to seconds\n              \n              # Append each track to the data frame\n              playlist_data &lt;- append(playlist_data, list(data.frame(\n                playlist_name = playlist_name,\n                playlist_id = playlist_id,\n                playlist_position = playlist_position,\n                playlist_followers = playlist_followers,\n                artist_name = artist_name,\n                track_name = track_name,\n                track_id = track_id,\n                album_name = album_name,\n                album_id = album_id,\n                duration = duration\n              )))\n              \n              playlist_position &lt;- playlist_position + 1\n            }\n          } else {\n            print(paste(\"No tracks found for playlist:\", playlist$name))\n          }\n        }\n      } else {\n        print(\"No playlists found in this file.\")\n      }\n    }, error = function(e) {\n      print(paste(\"Error reading file:\", file, \"- Possible non-JSON content\"))\n    })\n  }\n  \n  # Combine all the individual data frames into one\n  if (length(playlist_data) &gt; 0) {\n    playlist_df &lt;- bind_rows(playlist_data)\n    return(playlist_df)\n  } else {\n    return(tibble())  # Return an empty tibble if no data\n  }\n}"
  },
  {
    "objectID": "mp03.html#song-characteristics-dataset",
    "href": "mp03.html#song-characteristics-dataset",
    "title": "Mini Project 3",
    "section": "üéµ Song Characteristics Dataset",
    "text": "üéµ Song Characteristics Dataset\n\n\nShow Code\nload_songs &lt;- function() {\n  library(readr)\n  library(dplyr)\n  library(tidyr)\n  library(stringr)\n\n  # Define directory, file path, and URL\n  dir_path &lt;- \"data/mp03\"\n  file_path &lt;- file.path(dir_path, \"songs.csv\")\n  url &lt;- \"https://raw.githubusercontent.com/gabminamedez/spotify-data/refs/heads/master/data.csv\"\n\n  # Create directory if it doesn't exist\n  if (!dir.exists(dir_path)) {\n    dir.create(dir_path, recursive = TRUE)\n  }\n\n  # Download the file if it doesn't exist\n  if (!file.exists(file_path)) {\n    download.file(url, file_path, method = \"libcurl\")\n  }\n\n  # Read the CSV\n  SONGS &lt;- read_csv(file_path, show_col_types = FALSE)\n\n  # Clean and split artist list\n  SONGS_clean &lt;- SONGS |&gt;\n    mutate(\n      artists = str_remove_all(artists, \"\\\\[|\\\\]|'\")\n    ) |&gt;\n    separate_rows(artists, sep = \",\\\\s*\") |&gt;\n    rename(artist = artists)\n\n  return(SONGS_clean)\n}\n\nsongs_df &lt;- load_songs()\n\nlibrary(knitr)\n\nsongs_df |&gt;\n  select(name, artist, danceability, energy, valence, duration_ms) |&gt;\n  head(10) |&gt;\n  kable(caption = \"Song Characteristics\")\n\n\n\nSong Characteristics\n\n\n\n\n\n\n\n\n\n\nname\nartist\ndanceability\nenergy\nvalence\nduration_ms\n\n\n\n\nSingende Bataillone 1. Teil\nCarl Woitschach\n0.708\n0.1950\n0.7790\n158648\n\n\nFantasiest√ºcke, Op. 111: Pi√π tosto lento\nRobert Schumann\n0.379\n0.0135\n0.0767\n282133\n\n\nFantasiest√ºcke, Op. 111: Pi√π tosto lento\nVladimir Horowitz\n0.379\n0.0135\n0.0767\n282133\n\n\nChapter 1.18 - Zamek kaniowski\nSeweryn Goszczy≈Ñski\n0.749\n0.2200\n0.8800\n104300\n\n\nBebamos Juntos - Instrumental (Remasterizado)\nFrancisco Canaro\n0.781\n0.1300\n0.7200\n180760\n\n\nPolonaise-Fantaisie in A-Flat Major, Op. 61\nFr√©d√©ric Chopin\n0.210\n0.2040\n0.0693\n687733\n\n\nPolonaise-Fantaisie in A-Flat Major, Op. 61\nVladimir Horowitz\n0.210\n0.2040\n0.0693\n687733\n\n\nScherzo a capriccio: Presto\nFelix Mendelssohn\n0.424\n0.1200\n0.2660\n352600\n\n\nScherzo a capriccio: Presto\nVladimir Horowitz\n0.424\n0.1200\n0.2660\n352600\n\n\nValse oubli√©e No.¬†1 in F-Sharp Major, S. 215/1\nFranz Liszt\n0.444\n0.1970\n0.3050\n136627"
  },
  {
    "objectID": "mp03.html#spotify-million-playlist-dataset",
    "href": "mp03.html#spotify-million-playlist-dataset",
    "title": "Mini Project 3",
    "section": "üìù Spotify Million Playlist Dataset",
    "text": "üìù Spotify Million Playlist Dataset\nDue to ongoing issues with the GitHub repository originally hosting the Spotify Million Playlist Dataset (flagged by students and the professor), only a single JSON file mpd.slice.0-999.json was accessible. While this limits broader generalization, the selected slice provides a representative sample to conduct exploratory analysis.\n\n\nShow Code\nlibrary(httr)\nlibrary(jsonlite)\nlibrary(knitr)\nlibrary(dplyr)\nlibrary(tibble)\n\n# Define file details\nbase_url &lt;- \"https://raw.githubusercontent.com/DevinOgrady/spotify_million_playlist_dataset/refs/heads/main/data1/\"\nfile_name &lt;- \"mpd.slice.0-999.json\"\nfile_url &lt;- paste0(base_url, file_name)\nlocal_file_path &lt;- file.path(\"spotify_data\", file_name)\n\n# Download JSON file if not already present\nif (!file.exists(local_file_path)) {\n  response &lt;- GET(file_url)\n  if (status_code(response) == 200) {\n    dir.create(\"spotify_data\", showWarnings = FALSE)\n    writeBin(content(response, \"raw\"), local_file_path)\n    message(\"Downloaded: \", file_name)\n  } else {\n    stop(\"Error downloading file. Status code: \", status_code(response))\n  }\n}\n\n# Load just a few playlists and tracks to avoid overload\nif (file.exists(local_file_path)) {\n  json_data &lt;- fromJSON(local_file_path, simplifyDataFrame = FALSE)\n\n  # Extract only the first 5 playlists and 2 tracks from each\n  small_sample &lt;- lapply(json_data$playlists[1:10], function(pl) {\n    tibble(\n      Playlist_Name = pl$name,\n      Track_1 = pl$tracks[[1]]$track_name,\n      Track_2 = pl$tracks[[2]]$track_name\n    )\n  })\n\n\n  sample_df &lt;- bind_rows(small_sample)\n  kable(sample_df, caption = \"Playlists with 2 Tracks Each\", align = 'l')\n  \n} else {\n  print(\"No data found to load.\")\n}\n\n\n\nPlaylists with 2 Tracks Each\n\n\n\n\n\n\n\nPlaylist_Name\nTrack_1\nTrack_2\n\n\n\n\nThrowbacks\nLose Control (feat. Ciara & Fat Man Scoop)\nToxic\n\n\nAwesome Playlist\nEye of the Tiger\nLibera Me From Hell (Tengen Toppa Gurren Lagann)\n\n\nkorean\nLike You\nGOOD (feat. ELO)\n\n\nmat\nDanse macabre\nPiano concerto No.¬†2 in G Minor, Op. 22: Piano concerto No.¬†2 in G Minor, Op. 22: II. Allegro scherzando\n\n\n90s\nTonight, Tonight\nWonderwall - Remastered\n\n\nWedding\nTeach Me How to Dougie\nParty In The U.S.A.\n\n\nI Put A Spell On You\nI Put A Spell On You\nBury Us Alive\n\n\n2017\nHard To See You Happy\nOne Thousand Times\n\n\nBOP\nTwice\n7\n\n\nold country\nHighwayman\nHighwayman"
  },
  {
    "objectID": "mp03.html#questions",
    "href": "mp03.html#questions",
    "title": "Mini Project 3",
    "section": "üìä Questions",
    "text": "üìä Questions\n\nIdentifying Characteristics of Popular Songs\n1. How many distinct tracks and artists are represented in the playlist data?\n\n\nShow Code\nlibrary(dplyr)\nlibrary(knitr)\n\n# Remove duplicate track-artist combinations\nsongs_unique &lt;- songs_df |&gt; distinct(name, artist, .keep_all = TRUE)\n\n# Calculate distinct counts\ndistinct_counts &lt;- tibble(\n  Metric = c(\"Distinct Tracks\", \"Distinct Artists\"),\n  Count = c(\n    songs_unique |&gt; distinct(name) |&gt; nrow(),\n    songs_unique |&gt; distinct(artist) |&gt; nrow()\n  )\n)\n\n# Display\nkable(distinct_counts, caption = \"üéº Overview of Unique Tracks and Artists\", align = 'l')\n\n\n\nüéº Overview of Unique Tracks and Artists\n\n\nMetric\nCount\n\n\n\n\nDistinct Tracks\n132939\n\n\nDistinct Artists\n27755\n\n\n\n\n\n2. What are the 5 most popular tracks in the playlist data?\n\n\nShow Code\n# Top 5 most popular tracks \ntop_5_popular_tracks &lt;- songs_df |&gt;\n  group_by(name) |&gt;\n  slice_max(order_by = popularity, n = 1, with_ties = FALSE) |&gt;\n  ungroup() |&gt;\n  arrange(desc(popularity)) |&gt;\n  slice_head(n = 5) |&gt;\n  select(Track = name, Popularity = popularity)\n\nkable(top_5_popular_tracks, caption = \"üéß Top 5 Most Popular Tracks\", align = 'l')\n\n\n\nüéß Top 5 Most Popular Tracks\n\n\nTrack\nPopularity\n\n\n\n\nBlinding Lights\n100\n\n\nROCKSTAR (feat. Roddy Ricch)\n99\n\n\ndeath bed (coffee for your head) (feat. beabadoobee)\n97\n\n\nTHE SCOTTS\n96\n\n\nSupalonely\n95\n\n\n\n\n\n3. What is the most popular track in the playlist data that does not have a corresponding entry in the song characteristics data?\n\n\nShow Code\nplaylist_tracks &lt;- sample_df |&gt;\n  pivot_longer(cols = starts_with(\"Track_\"), names_to = \"track_slot\", values_to = \"name\")\n\n# Count appearances of each track in playlists\nplaylist_track_counts &lt;- playlist_tracks |&gt;\n  group_by(name) |&gt;\n  summarise(playlist_count = n(), .groups = 'drop')\n\n# Find tracks not in songs_df (i.e., no song characteristics)\nmissing_tracks &lt;- playlist_track_counts |&gt;\n  anti_join(songs_df, by = \"name\")\n\n# Get the most frequent missing track\nmost_common_missing_track &lt;- missing_tracks |&gt;\n  arrange(desc(playlist_count)) |&gt;\n  slice_head(n = 1)\n\nkable(most_common_missing_track, caption = \"üö´ Most Common Playlist Track Missing from Songs Data\", align = 'l')\n\n\n\nüö´ Most Common Playlist Track Missing from Songs Data\n\n\nname\nplaylist_count\n\n\n\n\nBury Us Alive\n1\n\n\n\n\n\n4. According to the song characteristics data, what is the most ‚Äúdanceable‚Äù track? How often does it appear in a playlist?\n\n\nShow Code\n# Identify the most danceable track\nmost_danceable_track &lt;- songs_df |&gt;\n  arrange(desc(danceability)) |&gt;\n  slice_head(n = 1) |&gt;\n  select(name, danceability)\n\n# Count how many times this track appears in playlists\nmost_danceable_count &lt;- songs_df |&gt;\n  filter(name == most_danceable_track$name) |&gt;\n  count()\n\n# Display the most danceable track info\nkable(\n  most_danceable_track,\n  caption = \"üé∂ Most Danceable Track\",\n  align = 'l'\n)\n\n\n\nüé∂ Most Danceable Track\n\n\nname\ndanceability\n\n\n\n\nFunky Cold Medina\n0.988\n\n\n\n\n\nShow Code\n# Display how many times it appears\nkable(\n  tibble(Appearances = most_danceable_count$n),\n  caption = \"üìä Playlist Appearances of Most Danceable Track\",\n  align = 'c'\n)\n\n\n\nüìä Playlist Appearances of Most Danceable Track\n\n\nAppearances\n\n\n\n\n1\n\n\n\n\n\n5. Which playlist has the longest average track length?\n\n\nShow Code\nlibrary(scales)  # for formatting time\n\n# Find the track with the longest duration\nlongest_track &lt;- songs_df |&gt;\n  arrange(desc(duration_ms)) |&gt;\n  slice_head(n = 1) |&gt;\n  select(name, duration_ms)\n\n# Convert duration from milliseconds to minutes and seconds\nlongest_track &lt;- longest_track |&gt;\n  mutate(duration_formatted = sprintf(\"%d:%02d\", duration_ms %/% 60000, (duration_ms %% 60000) %/% 1000)) |&gt;\n  select(name, duration_formatted)\n\n# Display formatted table\nkable(\n  longest_track,\n  caption = \"‚è±Ô∏è Longest Track by Duration\",\n  col.names = c(\"Track Name\", \"Duration (min:sec)\"),\n  align = 'l'\n)\n\n\n\n‚è±Ô∏è Longest Track by Duration\n\n\nTrack Name\nDuration (min:sec)\n\n\n\n\nBrown Noise - 90 Minutes\n90:03\n\n\n\n\n\n6. What is the most popular playlist on Spotify?\n\n\nShow Code\nlibrary(dplyr)\nlibrary(knitr)\n\n# Find the most popular track in the dataset\nmost_popular_track &lt;- songs_df |&gt;\n  arrange(desc(popularity)) |&gt;\n  slice_head(n = 1) |&gt;\n  select(name, popularity)\n\n# Display the most popular track \nkable(\n  most_popular_track,\n  caption = \"üé∂ Most Popular Track\",\n  col.names = c(\"Track Name\", \"Popularity Score\"),\n  align = 'l',\n  format = \"pipe\"\n)\n\n\n\nüé∂ Most Popular Track\n\n\nTrack Name\nPopularity Score\n\n\n\n\nBlinding Lights\n100"
  },
  {
    "objectID": "mp03.html#finding-related-songs",
    "href": "mp03.html#finding-related-songs",
    "title": "Mini Project 3",
    "section": "Finding Related Songs",
    "text": "Finding Related Songs\nWant to see the final playlist?\nüéß Jump to Featured Playlist\nTo build a cohesive playlist, I began by selecting two anchor songs that reflect the desired energy and style. I then used a data-driven approach to generate a list of potential tracks, curated the final playlist, and analyzed its dynamic flow.\n1. Selected Anchor Songs:\n‚ÄúBlinding Lights‚Äù by The Weeknd\n‚ÄúROCKSTAR‚Äù (feat. Roddy Ricch) by DaBaby\nThese anchor songs were selected for their contrasting yet complementary energy profiles. ‚ÄúBlinding Lights‚Äù has an upbeat synth-driven vibe, while ‚ÄúROCKSTAR‚Äù adds a darker, more intense rhythm, creating a diverse foundation for the playlist.\n2. Finding Candidates\nI applied several criteria to identify a pool of over 20 candidate tracks, ensuring a mix of familiar hits and lesser-known tracks:\nPopularity: Songs with a popularity score of 80 or higher were included to ensure mainstream appeal.\nKey & Tempo: Tracks that shared a similar key and tempo were selected to guarantee smooth transitions and maintain the energy flow.\nAnchor Artist: Additional songs by The Weeknd and DaBaby were included to retain stylistic continuity and cater to fan favorites.\nRelease Year & Features: I prioritized tracks released in the same year as the anchors, considering attributes like acousticness, danceability, and loudness to maintain an era-specific feel.\nMood & Energy Clustering: Songs were clustered based on mood-related features like energy, valence, and instrumentalness, ensuring a consistent emotional tone.\nOutcome: This process resulted in a curated pool of 20+ tracks, each selected based on one or more of the criteria above. The balance of popular hits and undiscovered gems ensures an engaging listening experience.\n3. Curated Playlist (12 Songs)\nFrom the candidate pool, I selected 12 tracks to create a balanced mix of familiarity and novelty:\nDiscovery: At least 2 tracks were new to me, offering a fresh listening experience.\nNon-Popular: I made sure to include at least 3 songs with a popularity score below 50, bringing diversity to the playlist.\nThe final order of the songs was determined by aligning their tempo, key, and energy levels, creating a seamless and engaging narrative flow.\n4. Energy Flow Visualization\n\n\nEnergy Flow\nlibrary(dplyr)\nlibrary(ggplot2)\n\n# Define anchor songs\nanchor_songs &lt;- c(\"Blinding Lights\", \"ROCKSTAR\")\n\n# Filter songs_df for anchor and other popular tracks\nplaylist_df &lt;- songs_df |&gt; \n  filter(name %in% anchor_songs | popularity &gt;= 80) |&gt; \n  distinct(name, .keep_all = TRUE) |&gt; \n  arrange(desc(popularity))\n\n# Build 12-song playlist starting with anchors\nplaylist_songs &lt;- unique(c(anchor_songs, playlist_df$name))\nplaylist_songs &lt;- playlist_songs[1:12]\n\n# Get metrics for those songs\nplaylist_metrics &lt;- songs_df |&gt; \n  filter(name %in% playlist_songs) |&gt; \n  distinct(name, .keep_all = TRUE) |&gt; \n  select(name, energy, danceability, tempo, popularity)\n\nmissing_songs &lt;- setdiff(playlist_songs, playlist_metrics$name)\nif (length(missing_songs) &gt; 0) {\n  playlist_metrics &lt;- bind_rows(\n    playlist_metrics,\n    data.frame(\n      name = missing_songs,\n      energy = NA,\n      danceability = NA,\n      tempo = NA,\n      popularity = NA\n    )\n  )\n}\n\n# Reorder for plotting\nplaylist_metrics$name &lt;- factor(playlist_metrics$name, levels = playlist_songs)\n\n# Plot energy rollercoaster\nggplot(playlist_metrics, aes(x = name, y = energy, fill = energy)) +\n  geom_col(width = 0.8, na.rm = TRUE) +\n  scale_fill_gradient(low = \"lightblue\", high = \"darkblue\", na.value = \"gray90\") +\n  scale_y_continuous(expand = expansion(mult = c(0, 0.1))) +\n  coord_flip() +\n  labs(\n    title = \"Energy Rollercoaster of The Ultimate Workout Journey\",\n    x = \"Track Order\",\n    y = \"Energy\"\n  ) +\n  theme_minimal(base_size = 12) +\n  theme(axis.text = element_text(size = 10))\n\n\n\n\n\n\n\n\n\n5. Final Playlist Overview\nName: The Ultimate Workout Journey\nDescription: A carefully crafted blend of chart-topping hits and lesser-known anthems that flow seamlessly, powering you through every stage of your workout.\nKey Takeaways:\nBalanced familiar hits with fresh discoveries to maintain both energy and variety.\nEnsured smooth transitions in energy and tempo to keep the listener engaged throughout.\nAdded strategic surprises to encourage curiosity and enhance replayability.\nShowcased the value of combining data-driven analysis with thoughtful thematic curation to create an immersive listening experience."
  },
  {
    "objectID": "mp03.html#curating-and-analyzing-the-ultimate-playlist",
    "href": "mp03.html#curating-and-analyzing-the-ultimate-playlist",
    "title": "Spotify Songs Analysis",
    "section": "Curating and Analyzing the Ultimate Playlist",
    "text": "Curating and Analyzing the Ultimate Playlist\nObjective: In this task, I curated my ultimate playlist, ensuring it had thematic unity and a well-considered flow. The final playlist was created not just based on data, but also by considering the emotional and musical journey that the listener would experience.\nStep 1: Playlist Structure and Thematic Unity The playlist I curated has a thematic unity centered around high-energy songs mixed with a few calmer, lesser-known tracks to give it variety and emotional depth. The overall mood is upbeat, making it ideal for a workout or a high-energy activity. The playlist starts with well-known hits to engage the listener and then transitions into deeper cuts, keeping the experience fresh.\nStep 2: Playlist Name and Description Playlist Name: ‚ÄúThe Ultimate Workout Playlist‚Äù\nDescription: A playlist designed to power you through any workout, with high-energy tracks to get you moving and lesser-known gems to keep you focused and engaged. From ‚ÄúBlinding Lights‚Äù to underground hits, this playlist rises and falls with the energy you need to stay motivated.\nStep 3: Design Principles Flow: I ensured that the playlist flows naturally, with gradual changes in energy and tempo. The playlist starts strong, maintaining a high level of energy throughout, with some transitions into deeper cuts as the tempo slows toward the end.\nCreativity: I deliberately included songs I was unfamiliar with and some lesser-known tracks, ensuring the playlist wasn‚Äôt just a collection of hits but an exploration of new sounds.\nStatistical Considerations: The final playlist includes a balance of popular tracks and lesser-known songs. This ensures that the playlist isn‚Äôt too predictable, while still maintaining an engaging energy level throughout.\nStep 4: Visualizing the Playlist Below is a visualization of how the playlist‚Äôs energy changes as the song order progresses, showcasing the rise and fall of the playlist‚Äôs energy:\n\n\nPopularity by Genre\nggplot(playlist_metrics, aes(x = reorder(name, -energy), y = energy)) +\n  geom_bar(stat = \"identity\", fill = \"steelblue\") +\n  coord_flip() +\n  labs(title = \"Energy Flow of The Ultimate Workout Playlist\",\n       x = \"Song\",\n       y = \"Energy Level\") +\n  theme_minimal() +\n  theme(axis.text.x = element_text(angle = 45, hjust = 1))"
  },
  {
    "objectID": "mp03.html#featured-playlist",
    "href": "mp03.html#featured-playlist",
    "title": "Mini Project 3",
    "section": "üéß Featured Playlist",
    "text": "üéß Featured Playlist"
  },
  {
    "objectID": "mp03.html#the-ultimate-workout-journey",
    "href": "mp03.html#the-ultimate-workout-journey",
    "title": "Mini Project 3",
    "section": "üéß The Ultimate Workout Journey",
    "text": "üéß The Ultimate Workout Journey"
  },
  {
    "objectID": "mp03.html#visually-identifying-characteristics-of-popular-songs",
    "href": "mp03.html#visually-identifying-characteristics-of-popular-songs",
    "title": "Mini Project 3",
    "section": "üìâ Visually Identifying Characteristics of Popular Songs",
    "text": "üìâ Visually Identifying Characteristics of Popular Songs\nThis section visually explores various aspects of popular Spotify songs. We start by examining the correlation between popularity and playlist appearances, finding a moderate positive relationship. A bar plot of release years highlights the dominance of recent years in shaping user preferences, particularly the top 5% most popular songs.\nDanceability peaked in the early 2010s, as shown by a line plot, while a bar plot reveals the 2000s and 2010s as the most represented decades. A polar plot of musical key frequencies shows a balanced distribution, and a histogram indicates a preference for medium-length songs, with shorter tracks slightly more common.\nFinally, a scatter plot suggests a slight positive correlation between energy and popularity, and the distribution of valence scores shows that users favor songs with more positive moods.\n1. Is the popularity column correlated with the number of playlist appearances?\n\n\nShow Code\n# Correlation between popularity and number of playlist appearances\nlibrary(ggplot2)\n\n# Summarize the number of appearances\ntrack_appearances &lt;- songs_df %&gt;%\n  group_by(name) %&gt;%\n  summarise(num_appearances = n(), popularity = mean(popularity, na.rm = TRUE)) %&gt;%\n  arrange(desc(num_appearances))\n\n# Scatter plot with linear regression line\nggplot(track_appearances, aes(x = num_appearances, y = popularity)) +\n  geom_point(color = \"steelblue\") +\n  geom_smooth(method = \"lm\", color = \"red\") +\n  labs(title = \"Correlation Between Popularity and Number of Playlist Appearances\",\n       x = \"Number of Playlist Appearances\",\n       y = \"Popularity\") +\n  theme_minimal()\n\n\n\n\n\n\n\n\n\n2. In what year were the most popular songs released?\n\n\nShow Code\n# Filter top popular songs and extract release years\ntop_popular_songs &lt;- songs_df %&gt;%\n  filter(popularity &gt; quantile(popularity, 0.95, na.rm = TRUE))  # Top 5% most popular songs\n\n# Remove rows where 'year' is missing\ntop_popular_songs &lt;- top_popular_songs %&gt;%\n  filter(!is.na(year))\n\n# Display top 5 popular release years with their song count\ntop_popular_songs_summary &lt;- top_popular_songs %&gt;%\n  group_by(year) %&gt;%\n  summarise(song_count = n()) %&gt;%\n  arrange(desc(song_count)) %&gt;%\n  slice_head(n = 10)  # Show only top 10\n\n# Display the table\nkable(\n  top_popular_songs_summary,\n  caption = \"Top 5 Popular Songs by Release Year\",\n  col.names = c(\"Release Year\", \"Number of Songs\"),\n  align = 'l',\n  format = \"pipe\"\n)\n\n\n\nTop 5 Popular Songs by Release Year\n\n\nRelease Year\nNumber of Songs\n\n\n\n\n2019\n2031\n\n\n2020\n1580\n\n\n2018\n1431\n\n\n2017\n999\n\n\n2016\n541\n\n\n2015\n414\n\n\n2014\n276\n\n\n2013\n225\n\n\n2012\n182\n\n\n2011\n181\n\n\n\n\n\nShow Code\n# Plot release years for these top songs\nggplot(top_popular_songs, aes(x = year)) +\n  geom_bar(fill = \"darkgreen\") +\n  labs(title = \"Release Year Distribution of Most Popular Songs\",\n       x = \"Release Year\",\n       y = \"Count of Songs\") +\n  theme_minimal()\n\n\n\n\n\n\n\n\n\n3. In what year did danceability peak?\n\n\nShow Code\n# Calculate the average danceability score per year\ndanceability_by_year &lt;- songs_df %&gt;%\n  group_by(year) %&gt;%\n  summarise(avg_danceability = mean(danceability, na.rm = TRUE))\n\n# Plot the danceability trend over the years\nggplot(danceability_by_year, aes(x = year, y = avg_danceability)) +\n  geom_line(color = \"purple\", size = 1) +\n  labs(title = \"Trend of Danceability by Year\",\n       x = \"Year\",\n       y = \"Average Danceability Score\") +\n  theme_minimal()\n\n\n\n\n\n\n\n\n\n4. Which decade is most represented on user playlists?\n\n\nShow Code\n# Create a new column for the decade\nsongs_df &lt;- songs_df %&gt;%\n  mutate(decade = floor(year / 10) * 10)\n\n# Plot the most represented decades\nggplot(songs_df, aes(x = as.factor(decade))) +\n  geom_bar(fill = \"orange\") +\n  labs(title = \"Most Represented Decades in User Playlists\",\n       x = \"Decade\",\n       y = \"Number of Songs\") +\n  theme_minimal()\n\n\n\n\n\n\n\n\n\n5.Create a plot of key frequency among songs.\n\n\nShow Code\n# Assuming songs_df has a 'key' column representing the key of the song\nggplot(songs_df, aes(x = as.factor(key))) +\n  geom_bar(fill = \"cornflowerblue\") +\n  coord_polar(start = 0) +\n  labs(title = \"Frequency of Musical Keys Among Songs\",\n       x = \"Musical Key\",\n       y = \"Frequency\") +\n  theme_minimal()\n\n\n\n\n\n\n\n\n\n6. What are the most popular track lengths?\n\n\nShow Code\n# Most popular track lengths with improvements for a cleaner chart\ntrack_length_popularity &lt;- songs_df |&gt;\n  mutate(track_length_min = duration_ms / 60000) |&gt;\n  group_by(track_length_min) |&gt;\n  summarise(popularity = mean(popularity, na.rm = TRUE)) |&gt;\n  arrange(desc(popularity))\n\n# Create a scatter plot with a smoother to show the trend\nggplot(track_length_popularity, aes(x = track_length_min, y = popularity)) +\n  geom_point(alpha = 0.5, size = 2, color = \"steelblue\") +  # Adjust transparency and size of points\n  geom_smooth(method = \"loess\", color = \"darkred\", se = FALSE) +  # Add a smoother line\n  labs(title = \"Track Length vs. Popularity\",\n       x = \"Track Length (minutes)\",\n       y = \"Popularity\") +\n  theme_minimal() +\n  theme(\n    plot.title = element_text(hjust = 0.5, size = 16),  # Center title and adjust font size\n    axis.title = element_text(size = 12),  # Adjust axis titles\n    axis.text = element_text(size = 10)  # Adjust axis labels\n  )\n\n\n\n\n\n\n\n\n\n7a. How does energy relate to popularity?\n\n\nPopularity by Genre\n# Plot energy vs popularity\nggplot(songs_df, aes(x = energy, y = popularity)) +\n  geom_point(color = \"darkblue\") +\n  geom_smooth(method = \"lm\", color = \"red\") +\n  labs(title = \"Energy vs Popularity\",\n       x = \"Energy\",\n       y = \"Popularity\") +\n  theme_minimal()\n\n\n\n\n\n\n\n\n\n7b. What is the distribution of valence (mood) scores across songs?\n\n\nPopularity by Genre\n# Plot distribution of valence\nggplot(songs_df, aes(x = valence)) +\n  geom_histogram(bins = 30, fill = \"lightblue\", color = \"black\", alpha = 0.7) +\n  labs(title = \"Distribution of Valence (Mood) Scores\",\n       x = \"Valence\",\n       y = \"Frequency\") +\n  theme_minimal()"
  },
  {
    "objectID": "mp03.html#conclusion",
    "href": "mp03.html#conclusion",
    "title": "Mini Project 3",
    "section": "üèÅ Conclusion",
    "text": "üèÅ Conclusion\n‚ÄúThe Ultimate Workout Journey‚Äù playlist blends data an alysis with creative curation to craft an engaging listening experience. By applying heuristics like playlist co-occurrence, key and tempo matching, and mood clustering, the playlist balances popular hits with hidden gems to ensure both familiarity and discovery. The energy flow was carefully structured to maintain listener engagement, with dynamic peaks and valleys that keep the experience fresh. Visualizing the energy trajectory confirmed the thoughtful progression of the playlist. This project showcases how data-driven decisions can enhance creative efforts, resulting in a playlist that captivates and motivates listeners, while offering room for future personalization and refinement."
  }
]